{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML 형태의 Oxford Pets 데이터 세트를 이용하여 Object Detection 및 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### annotation 디렉토리의 파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chulmin.kwon999/DLCV/data/ox_pet/annotations\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/chulmin.kwon999/DLCV/data/ox_pet/images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cfcff44fdf6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mIMAGE_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHOME_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DLCV/data/ox_pet/images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mANNO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IMAGE 파일 개수는:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'XML 파일 개수:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mANNO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mANNO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/chulmin.kwon999/DLCV/data/ox_pet/images'"
     ]
    }
   ],
   "source": [
    "# annotation과 image 디렉토리 설정. annotation디렉토리에 있는 파일 확인. \n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "HOME_DIR = str(Path.home())\n",
    "ANNO_DIR = os.path.join(HOME_DIR, 'DLCV/data/ox_pet/annotations')\n",
    "IMAGE_DIR = os.path.join(HOME_DIR, 'DLCV/data/ox_pet/images')\n",
    "print(ANNO_DIR)\n",
    "print('IMAGE 파일 개수는:',len(os.listdir(IMAGE_DIR)), 'XML 파일 개수:', len(os.listdir(ANNO_DIR)))\n",
    "os.listdir(ANNO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/DLCV/data/ox_pet/annotations/staffordshire_bull_terrier_128.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 파일에서 고유한 품종을 확인. \n",
    "files = os.listdir(ANNO_DIR)\n",
    "file_breed = [file[0:file.rfind('_')] for file in files if 'xml' in file]\n",
    "breed = list(set(file_breed))\n",
    "\n",
    "print(len(breed))\n",
    "print(breed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XML 파일을 읽어 CSV 형태의 파일로 생성하고 이를 pet_anno.csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "## filename에서 class명을 가져옴. xml 파일에는 class명이 class 대분류값인 cat/dog으로 되어 있음. \n",
    "def get_class_name_from_filename(file_name):\n",
    "    file_breed = file_name[0:file_name.rfind('_')]\n",
    "    return file_breed\n",
    "\n",
    "# XML 파일을 Pandas DataFrame으로 변환 한뒤 DataFrame의 to_csv()를 이용하여 csv 파일로 생성하고 DataFrame반환\n",
    "def xml_to_csv(path, output_filename):\n",
    "    xml_list = []\n",
    "    # xml 확장자를 가진 모든 파일의 절대 경로로 xml_file할당. \n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        # xml 파일을 parsing하여 XML Element형태의 Element Tree를 생성하여 object 정보를 추출. \n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        # 파일내에 있는 모든 object Element를 찾음. \n",
    "        for obj in root.findall('object'):\n",
    "            # filename, 이미지파일 크기, class명은 get_clas_name_from_filename()함수로 생성, 그리고 bounding box 위치 추출.\n",
    "            value = (os.path.join(IMAGE_DIR, root.find('filename').text),\n",
    "                    int(obj[4][0].text),\n",
    "                    int(obj[4][1].text),\n",
    "                    int(obj[4][2].text),\n",
    "                    int(obj[4][3].text),\n",
    "                    get_class_name_from_filename(root.find('filename').text),\n",
    "                    )\n",
    "            # object별 정보를 tuple형태로 xml_list에 저장. \n",
    "            xml_list.append(value)\n",
    "    # 모든 object별 정보를 DataFrame으로 생성하고 이를 CSV 파일로 생성하고 DataFrame은 반환. \n",
    "    column_name = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'class_name']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    xml_df.to_csv(os.path.join(path,output_filename), index=None, header=None)\n",
    "    return xml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation 디렉토리 밑에 pet_anno.csv로 저장\n",
    "pet_df = xml_to_csv(ANNO_DIR, os.path.join(ANNO_DIR, 'pet_anno.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(ANNO_DIR, 'pet_anno.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sort /home/younggi.kim999/DLCV/data/ox_pet/annotations/pet_anno.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class명과 class id 명 매핑을 클래스명의 알파벳 순으로 0부터 차례로 임의 매핑하고 이를 pet_class.txt파일에 저장. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = pet_df.groupby('class_name')['class_name'].max().to_list()\n",
    "class_ids = list(range(0, len(class_names)))\n",
    "print(class_names, class_ids)\n",
    "pd.DataFrame({'class_name':class_names, 'class_id':class_ids}).to_csv(os.path.join(ANNO_DIR, 'pet_class.txt'), header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_df.groupby('class_name')['class_name'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/DLCV/data/ox_pet/annotations/pet_class.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = pet_df.groupby('class_name')['class_name'].max().to_list()\n",
    "class_ids = list(range(0, len(class_names)))\n",
    "labels_to_names = pd.DataFrame({'class_name':class_names, 'class_Id':class_ids}).to_dict()['class_name']\n",
    "labels_to_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oxford pets 데이터 세트 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO 데이터 세트로 Pretrained된 모델이 keras-retinanet/snapshots 디렉토리에 저장되어 있는지 확인.  \n",
    "# 다운로드는 https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5 에서 받을 수 있음. \n",
    "# 해당 파일을 keras-retinanet/snapshots 디렉토리에 저장. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir, walk\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from os.path import join\n",
    "from keras_retinanet.bin.train import create_generators,create_models,create_callbacks\n",
    "from keras_retinanet.models import backbone,load_model,convert_model\n",
    "from keras_retinanet.utils.config import read_config_file,parse_anchor_parameters\n",
    "from keras_retinanet.utils.visualization import draw_boxes\n",
    "\n",
    "#from imgaug import augmenters as iaa\n",
    "\n",
    "tf.set_random_seed(31) # SEEDS MAKE RESULTS MORE REPRODUCABLE\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = backbone('resnet50')\n",
    "files = os.listdir(ANNO_DIR)\n",
    "\n",
    "\n",
    "class args:\n",
    "    batch_size = 16\n",
    "    config = None\n",
    "    random_transform = True # Image augmentation\n",
    "    annotations = os.path.join(ANNO_DIR, 'pet_anno.csv')\n",
    "    val_annotations = None\n",
    "    classes = os.path.join(ANNO_DIR, 'pet_class.txt')\n",
    "    image_min_side = 800\n",
    "    image_max_side = 1333\n",
    "    no_resize=None\n",
    "    dataset_type = 'csv'\n",
    "    tensorboard_dir = ''\n",
    "    evaluation = False\n",
    "    snapshots = True\n",
    "    snapshot_path = './keras-retinanet/snapshots/ox_pet'\n",
    "    backbone = 'resnet50'\n",
    "    epochs = 50\n",
    "    steps = len(files)//(batch_size)\n",
    "    weighted_average = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train용 generator 생성, valid용 generator는 데이터 부족으로 위 args 설정에서 None으로 함. \n",
    "train_gen,valid_gen = create_generators(args,b.preprocess_image)\n",
    "\n",
    "# retinanet 기반 네트웍 모델 설정. weight값을 아직 설정하지 않았으며, args config 설정. \n",
    "# model, training_model, prediction_model이 반환되나 이중 training_model만 사용\n",
    "model, training_model, prediction_model = create_models(\n",
    "            backbone_retinanet=b.retinanet,\n",
    "            num_classes=train_gen.num_classes(),\n",
    "            weights=None,\n",
    "            multi_gpu=False,\n",
    "            freeze_backbone=True,\n",
    "            lr=1e-3,\n",
    "            config=args.config)\n",
    "\n",
    "# callback 생성. epoch시 마다 발생하는 ModelCheckpoint, ReduceLROnPlateur callback 설정. \n",
    "callbacks = create_callbacks(model, training_model, prediction_model, valid_gen,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 모델의 초기 가중치를 coco pretrained weight로 설정\n",
    "training_model.load_weights('./keras-retinanet/snapshots/resnet50_coco_best_v2.1.0.h5',skip_mismatch=True,by_name=True)\n",
    "\n",
    "# 학습 수행. \n",
    "training_model.fit_generator(train_gen, steps_per_epoch=args.steps, epochs=args.epochs, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델은 https://drive.google.com/open?id=1n3rULHDZiD3zNUDydOoUoSopPJJeAxjx 에서 다운로드 가능 \n",
    "# 또는 github에서 다운로드 가능: https://github.com/chulminkw/DLCV/releases/download/1.0/resnet50_csv_50.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 모델을 inference 모델로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd ./keras-retinanet/snapshots; ls -lia\n",
    "# ./keras_retinanet/bin/convert_model.py \\ ~/DLCV/Detection/retina/keras-retinanet/snapshots/ox_pet/resnet50_csv_50.h5 \\ ~/DLCV/Detection/retina/keras-retinanet/snapshots/ox_pet/pet_inference.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet import models\n",
    "\n",
    "model_path = os.path.join('keras-retinanet','snapshots/ox_pet/pet_inference.h5')\n",
    "print(model_path)\n",
    "# load retinanet model\n",
    "pet_retina_model = models.load_model(model_path, backbone_name='resnet50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class id와 class name 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = pet_df.groupby('class_name')['class_name'].max().to_list()\n",
    "class_ids = list(range(0, len(class_names)))\n",
    "labels_to_names = pd.DataFrame({'class_name':class_names, 'class_id':class_ids}).to_dict()['class_name']\n",
    "labels_to_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inference 모델을 이용하여 이미지 Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "\n",
    "def get_detected_image_retina(model, img_array, use_copied_array, is_print=True):\n",
    "    \n",
    "    # copy to draw on\n",
    "    draw_img = None\n",
    "    if use_copied_array:\n",
    "        draw_img = img_array.copy()\n",
    "    else:\n",
    "        draw_img = img_array\n",
    "    \n",
    "    img_array = preprocess_image(img_array)\n",
    "    img_array, scale = resize_image(img_array)\n",
    "    \n",
    "    # process image\n",
    "    start = time.time()\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(img_array, axis=0))\n",
    "    if is_print:\n",
    "        print(\"object detection 처리 시간: \", round(time.time() - start,5))\n",
    "    \n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "\n",
    "    # visualize detections\n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        # scores are sorted so we can break\n",
    "        if score < 0.5:\n",
    "            break\n",
    "\n",
    "        color = label_color(label)\n",
    "\n",
    "        b = box.astype(int)\n",
    "        draw_box(draw_img, b, color=color)\n",
    "\n",
    "        caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "        draw_caption(draw_img, b, caption)\n",
    "    \n",
    "    if is_print:\n",
    "        print(\"이미지 processing 시간: \", round(time.time() - start,5))\n",
    "    \n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 'Sphynx_24.jpg' 'Russian_Blue_212.jpg', 'american_bulldog_66.jpg', 'pug_183.jpg'\n",
    "img_array  = cv2.imread(os.path.join(IMAGE_DIR, 'Russian_Blue_212.jpg'))\n",
    "detected_image = get_detected_image_retina(pet_retina_model,img_array, use_copied_array=True, is_print=True)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis('off')\n",
    "plt.imshow(detected_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 임의의 파일들을 Object Detection시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "np.random.seed(120)\n",
    "\n",
    "# 모든 이미지 파일중에서 임의의 16개 파일만 설정. \n",
    "all_image_files = glob.glob(IMAGE_DIR + '/*.jpg')\n",
    "all_image_files = np.array(all_image_files)\n",
    "file_cnt = all_image_files.shape[0]\n",
    "show_cnt = 16\n",
    "\n",
    "show_indexes = np.random.choice(file_cnt, show_cnt)\n",
    "show_files = all_image_files[show_indexes]\n",
    "print(show_files)\n",
    "\n",
    "detected_images = []\n",
    "for filename in show_files:\n",
    "    img_array = cv2.imread(os.path.join(IMAGE_DIR, filename))\n",
    "    detected_image = get_detected_image_retina(pet_retina_model,img_array, use_copied_array=True, is_print=True)\n",
    "    img_rgb = cv2.cvtColor(detected_image, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(detected_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습된 모델의 Object Detection 성능 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "HOME_DIR = str(Path.home())\n",
    "ANNO_DIR = os.path.join(HOME_DIR, 'DLCV/data/ox_pet/annotations')\n",
    "\n",
    "class args:\n",
    "    batch_size=16\n",
    "    dataset_type='csv'\n",
    "    score_threshold=0.05\n",
    "    iou_threshold=0.5\n",
    "    max_detections=100\n",
    "    image_min_side=800\n",
    "    image_max_side=1333\n",
    "    config=None\n",
    "    annotations=os.path.join(ANNO_DIR, 'pet_anno.csv')\n",
    "    classes=os.path.join(ANNO_DIR, 'pet_class.txt')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet.bin.evaluate import create_generator as eval_create_generator\n",
    "\n",
    "generator = eval_create_generator(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet.utils.eval import evaluate\n",
    "\n",
    "average_precisions = evaluate(\n",
    "            generator,\n",
    "            pet_retina_model,\n",
    "            iou_threshold=args.iou_threshold,\n",
    "            score_threshold=args.score_threshold,\n",
    "            max_detections=args.max_detections,\n",
    "            save_path=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print evaluation\n",
    "total_instances = []\n",
    "precisions = []\n",
    "for label, (average_precision, num_annotations) in average_precisions.items():\n",
    "    print('{:.0f} instances of class'.format(num_annotations),\n",
    "          generator.label_to_name(label), 'with average precision: {:.4f}'.format(average_precision))\n",
    "    total_instances.append(num_annotations)\n",
    "    precisions.append(average_precision)\n",
    "\n",
    "if sum(total_instances) == 0:\n",
    "    print('No test instances found.')\n",
    "\n",
    "#print('Inference time for {:.0f} images: {:.4f}'.format(generator.size(), inference_time))\n",
    "\n",
    "print('mAP using the weighted average of precisions among classes: {:.4f}'.format(sum([a * b for a, b in zip(total_instances, precisions)]) / sum(total_instances)))\n",
    "print('mAP: {:.4f}'.format(sum(precisions) / sum(x > 0 for x in total_instances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf115] *",
   "language": "python",
   "name": "conda-env-tf115-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

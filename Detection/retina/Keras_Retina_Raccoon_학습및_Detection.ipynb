{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raccoon 데이터 세트를 학습하고 학습된 모델을 이용하여 이미지와 비디오에 Object Detection과 성능 평가. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raccoon 데이터 세트의 image와 annotation 디렉토리 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "HOME_DIR = str(Path.home())\n",
    "\n",
    "ANNO_DIR = os.path.join(HOME_DIR, 'DLCV/data/raccoon/annotations')\n",
    "IMAGE_DIR = os.path.join(HOME_DIR, 'DLCV/data/raccoon/images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keras-retina 패키지의 사용 가능한 데이터 포맷\n",
    "* keras-retina 패키지는 VOC, COCO, Open Image, 그리고 csv 형태의 데이터포맷을 모두 사용 가능 \n",
    "* 하지만 VOC,COCO, OpenImage 모두 경연대회에서 사용된 디렉토리 구조가 필요함.   \n",
    "* Raccoon Dataset가 VOC와 비슷한 포맷이지만 정확하게 VOC 디렉토리 구조를 가지고 있지는 않으므로 간편하게 csv 형태의 데이터 포맷을 활용하여 데이터 입력 적용\n",
    "* csv 형태의 annotation과 class mapping format이 필요. annotation은 아래와 같이 표현 가능하며 하나의 오브젝트당 한 라인에서 comma로 정보를 분리함. 만일 하나의 이미지 파일에서 두개 이상의 오브젝트가 있다면 두개 이상의 라인으로 정보 표시.   \n",
    "/data/imgs/img_001.jpg,837,346,981,456,cow  \n",
    "/data/imgs/img_002.jpg,215,312,279,391,cat  \n",
    "/data/imgs/img_002.jpg,22,5,89,84,bird  \n",
    "/data/imgs/img_003.jpg,,,,,  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습과 검증 데이터 세트를 위한 별도의 annotation파일 생성. \n",
    "* keras-retina패키지는 validation annotation파일을 이용하여 학습 시 evaluation 수행 가능\n",
    "* 아래는 80%의 xml파일을 train csv로, 나머지 20% xml파일은 valid csv 로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "def get_train_valid_indexes(anno_path, valid_size ):\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    xml_files = [xml_file for xml_file in glob.glob(os.path.join(anno_path, '*.xml'))]\n",
    "    xml_files = np.array(xml_files)\n",
    "    total_cnt = xml_files.shape[0]\n",
    "    valid_cnt = int(total_cnt * valid_size)\n",
    "    \n",
    "    total_indexes = np.arange(0, total_cnt)\n",
    "    valid_indexes = np.random.choice(total_cnt, valid_cnt, replace=False)\n",
    "    train_indexes = total_indexes[~np.isin(total_indexes, valid_indexes)]\n",
    "    \n",
    "    return train_indexes, valid_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes, valid_indexes = get_train_valid_indexes(ANNO_DIR, 0.2)\n",
    "train_indexes.shape, valid_indexes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### csv annotation 데이터 파일을 만들기 위한 함수 생성. \n",
    "* 인자로 annotation 디렉토리명, csv형태로 만들어질 파일명을 주면 생성파일명으로 csv 형태의 annotation 데이터 파일 생성.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def xml_to_csv_sampling(path, output_filename, sample_index):\n",
    "    xml_list = np.array([xml_file for xml_file in glob.glob(path + '/*.xml')])\n",
    "    xml_list = xml_list[sample_index]\n",
    "    # xml 확장자를 가진 모든 파일의 절대 경로로 xml_file할당. \n",
    "    with open(output_filename, \"w\") as train_csv_file:\n",
    "        for xml_file in xml_list:\n",
    "            # xml 파일을 parsing하여 XML Element형태의 Element Tree를 생성하여 object 정보를 추출. \n",
    "            tree = ET.parse(xml_file)\n",
    "            root = tree.getroot()\n",
    "            # 파일내에 있는 모든 object Element를 찾음. \n",
    "            full_image_name = os.path.join(IMAGE_DIR, root.find('filename').text)\n",
    "            value_str_list = ' '\n",
    "            for obj in root.findall('object'):\n",
    "                xmlbox = obj.find('bndbox')\n",
    "                x1 = int(xmlbox.find('xmin').text)\n",
    "                y1 = int(xmlbox.find('ymin').text)\n",
    "                x2 = int(xmlbox.find('xmax').text)\n",
    "                y2 = int(xmlbox.find('ymax').text)\n",
    "                # 단 하나의 \n",
    "                class_name='raccoon'\n",
    "                value_str = ('{0},{1},{2},{3},{4},{5}').format(full_image_name,x1, y1, x2, y2, class_name)\n",
    "                # object별 정보를 tuple형태로 object_list에 저장. \n",
    "                train_csv_file.write(value_str+'\\n')\n",
    "        # xml file 찾는 for loop 종료 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes, valid_indexes = get_train_valid_indexes(ANNO_DIR, 0.2)\n",
    "xml_to_csv_sampling(ANNO_DIR, os.path.join(ANNO_DIR,'raccoon_anno_retina_train.csv'), train_indexes)\n",
    "xml_to_csv_sampling(ANNO_DIR, os.path.join(ANNO_DIR,'raccoon_anno_retina_valid.csv'), valid_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keras_retinanet/bin/train.py를 이용하여 학습 수행. \n",
    "* keras-retinanet 패키지는 학습시간이 비교적 오래 필요. \n",
    "* 특히 batch-size 가 크게 설정하기 어려움. 2이상 설정 시 메모리를 과다 사용으로 segmentation fault 오류 발생.\n",
    "* Shell에서 export TF_CUDNN_USE_AUTOTUNE=0  설정하면 batch-size를 2로 늘릴 수 있으나 큰 학습 시간 단축은 기대하기 어려움. \n",
    "* Raccoon 데이터 세트는 steps=200, epochs=20 정도면 충분한 학습이 가능. \n",
    "* 학습 시 epoch가 완료될 때마다 snapshots 디렉토리에 모델들을 계속 생성하여 저장. \n",
    "* train.py는 많은 환경 변수를 명령 인자로 입력해야함. 명령 인자로 입력하지 않을 경우 Default 환경 변수값으로 입력됨. Default 환경 변수값에 대한 이해 필요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래는 shell에서 수행해야 합니다. \n",
    "!./keras_retinanet/bin/train.py --epochs=20 --steps=200 \\\n",
    "  csv ~/DLCV/data/raccoon/annotations/raccoon_anno_retina_train.csv \\\n",
    "      ~/DLCV/data/raccoon/annotations/raccoon_class.txt \\\n",
    "      --val-annotations=/home/younggi.kim999/DLCV/data/raccoon/annotations/raccoon_anno_retina_valid.csv \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train.py의 여러 모듈을 직접 import하여 학습 수행. \n",
    "* train.py의 여러 모듈을 직접 import하여 customization으로 학습을 수행하는 것이 더 직관적이고 빠른 학습 시간 보장.\n",
    "* keras-retinanet으로 학습 시 어떻게 내부 모듈이 동작하는지 더 명확히 알 수 있음. \n",
    "* 환경 파라미터를 훨씬 편하게 조정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import listdir, walk\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from os.path import join\n",
    "from keras_retinanet.bin.train import create_generators,create_models,create_callbacks\n",
    "from keras_retinanet.models import backbone,load_model,convert_model\n",
    "from keras_retinanet.utils.config import read_config_file,parse_anchor_parameters\n",
    "from keras_retinanet.utils.visualization import draw_boxes\n",
    "\n",
    "#from imgaug import augmenters as iaa\n",
    "\n",
    "tf.set_random_seed(31) # SEEDS MAKE RESULTS MORE REPRODUCABLE\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 환경 파라미터 설정. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = backbone('resnet50')\n",
    "files = os.listdir(ANNO_DIR)\n",
    "train_file_cnt = train_indexes.shape[0]\n",
    "\n",
    "class args:\n",
    "    batch_size = 4\n",
    "    config = None\n",
    "    random_transform = True # Image augmentation\n",
    "    annotations = os.path.join(ANNO_DIR, 'raccoon_anno_retina_train.csv')\n",
    "    val_annotations = os.path.join(ANNO_DIR, 'raccoon_anno_retina_valid.csv')\n",
    "    classes = os.path.join(ANNO_DIR, 'raccoon_class.txt')\n",
    "    image_min_side = 800\n",
    "    image_max_side = 1333\n",
    "    no_resize=None\n",
    "    dataset_type = 'csv'\n",
    "    tensorboard_dir = ''\n",
    "    evaluation = True\n",
    "    snapshots = True\n",
    "    snapshot_path = './keras-retinanet/snapshots'\n",
    "    backbone = 'resnet50'\n",
    "    epochs = 20\n",
    "    steps = train_file_cnt//(batch_size)\n",
    "    weighted_average = True\n",
    "    # keras-retinanet 내부 버전 update로 추가 2020.07.31\n",
    "    #reduce_lr_patience = 2\n",
    "    #reduce_lr_factor = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습과 검증을 위한 generator 생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen,valid_gen = create_generators(args,b.preprocess_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backend CNN과 기타 환경 설정하여 기본 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, training_model, prediction_model = create_models(\n",
    "            backbone_retinanet=b.retinanet,\n",
    "            num_classes=train_gen.num_classes(),\n",
    "            weights=None,\n",
    "            multi_gpu=False,\n",
    "            freeze_backbone=True,\n",
    "            lr=1e-3,\n",
    "            config=args.config\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint, ReduceLROnPlateur와 같은 callback 기능 생성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = create_callbacks(\n",
    "    model,\n",
    "    training_model,\n",
    "    prediction_model,\n",
    "    valid_gen,\n",
    "    args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 모델에 coco로 pretrained된 weight를 최초 weight로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.load_weights('./keras-retinanet/snapshots/resnet50_coco_best_v2.1.0.h5',skip_mismatch=True,by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.fit_generator(generator=train_gen,\n",
    "        steps_per_epoch=args.steps,\n",
    "        epochs=args.epochs,\n",
    "        verbose=1,\n",
    "        validation_data=valid_gen,                     \n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 모델 기반 Object Detection 및 Detection 성능 평가(Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 모델을 Inference 모델로 변환\n",
    "*  keras_retinanet/bin/convert_model.py를 이용하여 snapshots 디렉토리에 가장 마지막에 만들어진 학습 모델(가장 손실율이 적은)을 infererence용 모델로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "# keras-retinanet 패키지 업데이트로 reduct_lr_paitence, reduce_lr_factor 추가 되면서 가장 마지막에 만들어진 학습 모델이 13 epoch\n",
    "# 에서 early stopping 됨. 가장 마지막 학습 모델 resnet50_csv_13.h4로 raccoon_inference.h5 수정. \n",
    "#! chmod +x ./keras-retinanet/keras_retinanet/bin/convert_model.py\n",
    "#!./keras-retinanet/keras_retinanet/bin/convert_model.py ~/DLCV/Detection/retina/keras-retinanet/snapshots/resnet50_csv_20.h5 \\\n",
    "#~/DLCV/Detection/retina/keras-retinanet/snapshots/raccoon_inference.h5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 변환된 inference용 모델인 raccoon_inference.h5 파일을 로드하여 이미지 Detection 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "#from keras_retinanet.utils.gpu import setup_gpu\n",
    "\n",
    "# use this to change which GPU to use\n",
    "gpu = 0\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "#setup_gpu(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "model_path = os.path.join(ROOT_DIR, 'keras-retinanet/snapshots/raccoon_inference.h5')\n",
    "\n",
    "print(model_path)\n",
    "# load retinanet model\n",
    "raccoon_retina_model = models.load_model(model_path, backbone_name='resnet50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 detect를 위한 함수 생성. \n",
    "* inference를 수행하기 전에 이미지 scaling 및 크기를 재 조정할 수 있도록 preprocess_image()와 resize_image() 제공. \n",
    "* keras-retinanet은 이미지에 bounding box를 편리하게 그릴 수 있는 API제공. draw_box(), draw_caption(), label_color() 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "\n",
    "labels_to_names_seq = {0:'Raccoon'}\n",
    "\n",
    "def get_detected_image_retina(model, img_array, use_copied_array, is_print=True):\n",
    "    \n",
    "    # copy to draw on\n",
    "    draw_img = None\n",
    "    if use_copied_array:\n",
    "        draw_img = img_array.copy()\n",
    "    else:\n",
    "        draw_img = img_array\n",
    "    \n",
    "    img_array = preprocess_image(img_array)\n",
    "    img_array, scale = resize_image(img_array)\n",
    "    \n",
    "    # process image\n",
    "    start = time.time()\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(img_array, axis=0))\n",
    "    if is_print:\n",
    "        print(\"object detection 처리 시간: \", round(time.time() - start,5))\n",
    "    \n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "\n",
    "    # visualize detections\n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        # scores are sorted so we can break\n",
    "        if score < 0.5:\n",
    "            break\n",
    "\n",
    "        color = label_color(label)\n",
    "\n",
    "        b = box.astype(int)\n",
    "        draw_box(draw_img, b, color=color)\n",
    "\n",
    "        caption = \"{} {:.3f}\".format(labels_to_names_seq[label], score)\n",
    "        draw_caption(draw_img, b, caption)\n",
    "    \n",
    "    if is_print:\n",
    "        print(\"이미지 processing 시간: \", round(time.time() - start,5))\n",
    "    \n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "HOME_DIR = str(Path.home())\n",
    "\n",
    "ANNO_DIR = os.path.join(HOME_DIR, 'DLCV/data/raccoon/annotations')\n",
    "IMAGE_DIR = os.path.join(HOME_DIR, 'DLCV/data/raccoon/images')\n",
    "\n",
    "img_array  = cv2.imread(os.path.join(IMAGE_DIR, 'raccoon-22.jpg'))\n",
    "draw_img_array = img_array.copy()\n",
    "draw_img_array = cv2.cvtColor(draw_img_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(draw_img_array)\n",
    "plt.show()\n",
    "\n",
    "detected_image = get_detected_image_retina(raccoon_retina_model, img_array, use_copied_array=True, is_print=True)\n",
    "img_rgb = cv2.cvtColor(detected_image, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# 모든 이미지 파일중에서 임의의 16개 파일만 설정. \n",
    "all_image_files = glob.glob(IMAGE_DIR + '/*.jpg')\n",
    "all_image_files = np.array(all_image_files)\n",
    "file_cnt = all_image_files.shape[0]\n",
    "show_cnt = 16\n",
    "\n",
    "show_indexes = np.random.choice(file_cnt, show_cnt)\n",
    "show_files = all_image_files[show_indexes]\n",
    "print(show_files)\n",
    "fig, axs = plt.subplots(figsize=(24,24) , ncols=4 , nrows=4)\n",
    "\n",
    "for i , filename in enumerate(show_files):\n",
    "    print(filename)\n",
    "    row = int(i/4)\n",
    "    col = i%4\n",
    "    img_array = cv2.imread(os.path.join(IMAGE_DIR, filename))\n",
    "    detected_image = get_detected_image_retina(raccoon_retina_model,img_array, use_copied_array=True, is_print=True)\n",
    "    img_rgb = cv2.cvtColor(detected_image, cv2.COLOR_BGR2RGB)\n",
    "    axs[row][col].imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### video에 object detection을 수행\n",
    "* get_detected_image()와 유사한 함수를 생성. 인자로 image array와 retina 모델을 입력, 개별 frame별로 object Detection 수행. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video_retina(model, input_path, output_path=\"\"):\n",
    "    \n",
    "    start = time.time()\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    vid_size= (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size)\n",
    "    \n",
    "    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print('총 Frame 갯수:', frame_cnt)\n",
    "    \n",
    "    while True:\n",
    "        hasFrame, image_frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            print('프레임이 없거나 종료 되었습니다.')\n",
    "            break\n",
    "\n",
    "        detected_image = get_detected_image_retina(model,image_frame, use_copied_array=False, is_print=True)\n",
    "        vid_writer.write(detected_image)\n",
    "    \n",
    "    vid_writer.release()\n",
    "    cap.release()\n",
    "    print('### Video Detect 총 수행시간:', round(time.time()-start, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_video_retina(raccoon_retina_model, input_path='../../data/video/jack_and_raccoon.mp4', output_path='../../data/output/jack_retina.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp ~/DLCV/data/output/jack_retina.avi gs://my_bucket_dlcv/data/output/jack_retina.avi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raccoon 데이터 세트 학습 모델의 Object Detection 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet.bin.evaluate import create_generator as eval_create_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "HOME_DIR = str(Path.home())\n",
    "ANNO_DIR = os.path.join(HOME_DIR, 'DLCV/data/raccoon/annotations')\n",
    "\n",
    "class args:\n",
    "    dataset_type='csv'\n",
    "    score_threshold=0.05\n",
    "    iou_threshold=0.5\n",
    "    max_detections=100\n",
    "    image_min_side=800\n",
    "    image_max_side=1333\n",
    "    config=None\n",
    "    annotations=os.path.join(ANNO_DIR, 'raccoon_anno_retina_valid.csv')\n",
    "    classes=os.path.join(ANNO_DIR, 'raccoon_class.txt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = eval_create_generator(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet.utils.eval import evaluate\n",
    "\n",
    "average_precisions = evaluate(\n",
    "            generator,\n",
    "            raccoon_retina_model,\n",
    "            iou_threshold=args.iou_threshold,\n",
    "            score_threshold=args.score_threshold,\n",
    "            max_detections=args.max_detections,\n",
    "            save_path=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print evaluation\n",
    "total_instances = []\n",
    "precisions = []\n",
    "for label, (average_precision, num_annotations) in average_precisions.items():\n",
    "    print('{:.0f} instances of class'.format(num_annotations),\n",
    "          generator.label_to_name(label), 'with average precision: {:.4f}'.format(average_precision))\n",
    "    total_instances.append(num_annotations)\n",
    "    precisions.append(average_precision)\n",
    "\n",
    "if sum(total_instances) == 0:\n",
    "    print('No test instances found.')\n",
    "\n",
    "#print('Inference time for {:.0f} images: {:.4f}'.format(generator.size(), inference_time))\n",
    "\n",
    "print('mAP using the weighted average of precisions among classes: {:.4f}'.format(sum([a * b for a, b in zip(total_instances, precisions)]) / sum(total_instances)))\n",
    "print('mAP: {:.4f}'.format(sum(precisions) / sum(x > 0 for x in total_instances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf115",
   "language": "python",
   "name": "tf115"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

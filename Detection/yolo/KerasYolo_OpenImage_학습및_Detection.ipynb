{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open Image Dataset의 Object Detection 학습 및 Inference\n",
    "* Open Image Dataset에서 Football 관련 Object, Fish관련 Object를 추출 후 학습 데이터 세트 생성. \n",
    "* 이를 이용하여 Object Detection 수행. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python3 main.py downloader --classes Football 'Football helmet' Fish Shark Shellfish  --type_csv train --multiclasses 1 --limit 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation과 image 디렉토리 설정. annotation디렉토리에 있는 파일 확인. \n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "HOME_DIR = str(Path.home())\n",
    "\n",
    "ANNO_DIR = os.path.join(HOME_DIR, 'DLCV/data/ballnfish/annotations')\n",
    "IMAGE_DIR = os.path.join(HOME_DIR, 'DLCV/data/ballnfish/images')\n",
    "print(ANNO_DIR)\n",
    "\n",
    "files = os.listdir(ANNO_DIR)\n",
    "print('파일 개수는:',len(files))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /home/younggi.kim999/DLCV/data/ballnfish/annotations/0a54e9aca3f0c0ef.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "classes_map = {'Football':0, 'Football_helmet':1, 'Fish':2, 'Shark':3, 'Shellfish':4 }\n",
    "\n",
    "def xml_to_csv(path, output_filename):\n",
    "    xml_list = []\n",
    "    # xml 확장자를 가진 모든 파일의 절대 경로로 xml_file할당. \n",
    "    with open(output_filename, \"w\") as train_csv_file:\n",
    "        for xml_file in glob.glob(path + '/*.xml'):\n",
    "            # xml 파일을 parsing하여 XML Element형태의 Element Tree를 생성하여 object 정보를 추출. \n",
    "            tree = ET.parse(xml_file)\n",
    "            root = tree.getroot()\n",
    "            # 파일내에 있는 모든 object Element를 찾음. \n",
    "            full_image_name = os.path.join(IMAGE_DIR, root.find('filename').text)\n",
    "            value_str_list = ' '\n",
    "            for obj in root.findall('object'):\n",
    "                xmlbox = obj.find('bndbox')\n",
    "                class_name = obj.find('name').text\n",
    "                x1 = int(xmlbox.find('xmin').text)\n",
    "                y1 = int(xmlbox.find('ymin').text)\n",
    "                x2 = int(xmlbox.find('xmax').text)\n",
    "                y2 = int(xmlbox.find('ymax').text)\n",
    "                # \n",
    "                class_id = classes_map[class_name]\n",
    "                value_str = ('{0},{1},{2},{3},{4}').format(x1, y1, x2, y2, class_id)\n",
    "                # object별 정보를 tuple형태로 object_list에 저장. \n",
    "                value_str_list = value_str_list+value_str+' '\n",
    "        \n",
    "            train_csv_file.write(full_image_name+' '+ value_str_list+'\\n')\n",
    "        # xml file 찾는 for loop 종료 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_to_csv(ANNO_DIR, os.path.join(ANNO_DIR,'ballnfish_anno.csv'))\n",
    "print(os.path.join(ANNO_DIR,'ballnfish_anno.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /home/younggi.kim999/DLCV/data/ballnfish/annotations/ballnfish_anno.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(cv2.cvtColor(cv2.imread('/home/younggi.kim999/DLCV/data/ballnfish/images/9c27811a78b74a48.jpg'), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "LOCAL_PACKAGE_DIR = os.path.abspath(\"./keras-yolo3\")\n",
    "sys.path.append(LOCAL_PACKAGE_DIR)\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import get_classes, get_anchors\n",
    "from train import create_model, data_generator, data_generator_wrapper\n",
    "\n",
    "BASE_DIR = os.path.join(HOME_DIR, 'DLCV/Detection/yolo/keras-yolo3')\n",
    "\n",
    "## 학습을 위한 기반 환경 설정. annotation 파일 위치, epochs시 저장된 모델 파일, Object클래스 파일, anchor 파일.\n",
    "annotation_path = os.path.join(ANNO_DIR, 'ballnfish_anno.csv')\n",
    "log_dir = os.path.join(BASE_DIR, 'snapshots/ballnfish/')\n",
    "classes_path = os.path.join(BASE_DIR, 'model_data/ballnfish_classes.txt')\n",
    "anchors_path = os.path.join(BASE_DIR,'model_data/yolo_anchors.txt')\n",
    "\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "print(class_names, num_classes)\n",
    "print(anchors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### yolo 모델 학습을 위한 전반적인 파라미터를 config 클래스로 설정하고 필요시 이를 수정하여 학습. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv annotation 파일을 읽어서 lines 리스트로 만듬. \n",
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "class config:\n",
    "    #tiny yolo로 모델로 초기 weight 학습 원할 시 아래를 tiny-yolo.h5로 수정. \n",
    "    initial_weights_path=os.path.join(BASE_DIR, 'model_data/yolo.h5' )\n",
    "    # input_shape는 고정. \n",
    "    input_shape=(416, 416)\n",
    "    # epochs는 freeze, unfreeze 2 step에 따라 설정. \n",
    "    first_epochs=50\n",
    "    first_initial_epochs=0\n",
    "    second_epochs=100\n",
    "    second_initial_epochs=50\n",
    "    # 학습시 batch size, train,valid건수, epoch steps 횟수  \n",
    "    batch_size = 4\n",
    "    val_split = 0.1   \n",
    "    num_val = int(len(lines)*val_split)\n",
    "    num_train = len(lines) - num_val\n",
    "    train_epoch_steps = num_train//batch_size \n",
    "    val_epoch_steps =  num_val//batch_size\n",
    "    \n",
    "    anchors = get_anchors(anchors_path)\n",
    "    class_names = get_classes(classes_path)\n",
    "    num_classes = len(class_names)\n",
    "    # epoch시 저장된 weight 파일 디렉토리 \n",
    "    log_dir = os.path.join(BASE_DIR, 'snapshots/ballnfish/')\n",
    "    \n",
    "print('Class name:', config.class_names,'\\nNum classes:', config.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### csv 파일을 입력 받아서 train 데이터와 valid 데이터 처리를 위한 data_generator_wrapper객체를 각각 생성.\n",
    "* train용, valid 용 data_generator_wrapper는 Yolo 모델의 fit_generator()학습시 인자로 입력됨. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(lines):\n",
    "    \n",
    "    train_data_generator = data_generator_wrapper(lines[:config.num_train], config.batch_size, \n",
    "                                                  config.input_shape, config.anchors, config.num_classes)\n",
    "    \n",
    "    valid_data_generator = data_generator_wrapper(lines[config.num_train:], config.batch_size, \n",
    "                                                  config.input_shape, config.anchors, config.num_classes)\n",
    "    \n",
    "    return train_data_generator, valid_data_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOLO 모델 또는 tiny yolo 모델 반환. 초기 weight값은 pretrained된 yolo weight값으로 할당. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchor 개수에 따라 tiny yolo 모델 또는 yolo 모델 반환. \n",
    "def create_yolo_model():\n",
    "    is_tiny_version = len(config.anchors)==6 \n",
    "    if is_tiny_version:\n",
    "        model = create_tiny_model(config.input_shape, config.anchors, config.num_classes, \n",
    "            freeze_body=2, weights_path=config.initial_weights_path)\n",
    "    else:\n",
    "        model = create_model(config.input_shape, config.anchors, config.num_classes, \n",
    "            freeze_body=2, weights_path=config.initial_weights_path)\n",
    "        \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### callback 객체들을 생성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping callback 반환\n",
    "def create_callbacks():\n",
    "    logging = TensorBoard(log_dir=config.log_dir)\n",
    "    checkpoint = ModelCheckpoint(config.log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "    \n",
    "    #개별 callback들을 한꺼번에 list로 묶어서 반환\n",
    "    return [logging, checkpoint, reduce_lr, early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# create_generator(), create_model(), create_callbacks() 수행. \n",
    "train_data_generator, valid_data_generator = create_generator(lines)\n",
    "ballnfish_model = create_yolo_model()\n",
    "callbacks_list = create_callbacks()\n",
    "\n",
    "# 최초 모델은 주요 layer가 freeze되어 있음. 안정적인 loss를 확보하기 위해 주요 layer를 freeze한 상태로 먼저 학습. \n",
    "print('First train 시작' )\n",
    "ballnfish_model.compile(optimizer=Adam(lr=1e-3), loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "ballnfish_model.fit_generator(train_data_generator, steps_per_epoch=config.train_epoch_steps,\n",
    "        validation_data=valid_data_generator, validation_steps=config.val_epoch_steps,\n",
    "        epochs=config.first_epochs, initial_epoch=config.first_initial_epochs, \n",
    "        callbacks=callbacks_list)\n",
    "\n",
    "# 1단계 학습 완료 모델 저장. \n",
    "ballnfish_model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "# 모든 layer를 trainable=True로 설정하고 학습 수행. \n",
    "for i in range(len(ballnfish_model.layers)):\n",
    "    ballnfish_model.layers[i].trainable = True\n",
    "    \n",
    "print('Second train 시작' )\n",
    "ballnfish_model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) \n",
    "ballnfish_model.fit_generator(train_data_generator, steps_per_epoch=config.train_epoch_steps,\n",
    "    validation_data=valid_data_generator, validation_steps=config.val_epoch_steps,\n",
    "    epochs=config.second_epochs, initial_epoch=config.second_initial_epochs,\n",
    "    callbacks=callbacks_list)\n",
    "\n",
    "# 최종 학습 완료 모델 저장. \n",
    "ballnfish_model.save_weights(log_dir + 'trained_weights_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 학습된 모델을 로딩하여 Object Detection 수행. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo import YOLO\n",
    "#keras-yolo에서 image처리를 주요 PIL로 수행. \n",
    "from PIL import Image\n",
    "\n",
    "LOCAL_PACKAGE_DIR = os.path.abspath(\"./keras-yolo3\")\n",
    "sys.path.append(LOCAL_PACKAGE_DIR)\n",
    "\n",
    "ballnfish_yolo = YOLO(model_path='/home/younggi.kim999/DLCV/Detection/yolo/keras-yolo3/snapshots/ballnfish/trained_weights_final.h5',\n",
    "            anchors_path='~/DLCV/Detection/yolo/keras-yolo3/model_data/yolo_anchors.txt',\n",
    "            classes_path='~/DLCV/Detection/yolo/keras-yolo3/model_data/ballnfish_classes.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_list = ['f1b492a9bce3ac9a.jpg', '1e6ff631bb0c198b.jpg', '97ac013310bda756.jpg',\n",
    "                'e5b1646c395aecfd.jpg', '53ef241dad498f6c.jpg', '02ccbf5ddaaecedb.jpg' ]\n",
    "for image_name in football_list:\n",
    "    img = Image.open(os.path.join(IMAGE_DIR, image_name))\n",
    "    detected_img = ballnfish_yolo.detect_image(img)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(detected_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helmet_list = ['1fed5c930211c6e0.jpg', '011a59a160d7a091.jpg', 'd39b46aa4bc0c165.jpg', '7e9eb7eba80e34e7.jpg', '9c27811a78b74a48.jpg']\n",
    "for image_name in helmet_list:\n",
    "    img = Image.open(os.path.join(IMAGE_DIR, image_name))\n",
    "    detected_img = ballnfish_yolo.detect_image(img)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(detected_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_list = ['25e42c55bfcbaa88.jpg', 'a571e4cdcfbcb79e.jpg', '872c435491f2b4d3.jpg', \n",
    "             'bebac23c45451d93.jpg', 'eba7caf07a26829b.jpg', 'dc607a2989bdc9dc.jpg' ]\n",
    "for image_name in fish_list:\n",
    "    img = Image.open(os.path.join(IMAGE_DIR, image_name))\n",
    "    detected_img = ballnfish_yolo.detect_image(img)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(detected_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_list = ['d92290f6c04dd83b.jpg', '3a37a09ec201cdeb.jpg', '32717894b5ce0052.jpg', 'a848df5dbed78a0f.jpg', '3283eafe11a847c3.jpg']\n",
    "for image_name in shark_list:\n",
    "    img = Image.open(os.path.join(IMAGE_DIR, image_name))\n",
    "    detected_img = ballnfish_yolo.detect_image(img)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(detected_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_list=['5cc89bc28084e8e8.jpg',  '055e756883766e1f.jpg', '089354fc39f5d82d.jpg', '80eddfdcb3384458.jpg']\n",
    "for image_name in shell_list:\n",
    "    img = Image.open(os.path.join(IMAGE_DIR, image_name))\n",
    "    detected_img = ballnfish_yolo.detect_image(img)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(detected_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 영상 Object Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "def detect_video_yolo(model, input_path, output_path=\"\"):\n",
    "    \n",
    "    start = time.time()\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    #codec = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    vid_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size)\n",
    "    \n",
    "    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print('총 Frame 갯수:', frame_cnt, '원본 영상 FPS:',vid_fps, '원본 Frame 크기:', vid_size)\n",
    "    index = 0\n",
    "    while True:\n",
    "        hasFrame, image_frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            print('프레임이 없거나 종료 되었습니다.')\n",
    "            break\n",
    "        start = time.time()\n",
    "        # PIL Package를 내부에서 사용하므로 cv2에서 읽은 image_frame array를 다시 PIL의 Image형태로 변환해야 함.  \n",
    "        image = Image.fromarray(image_frame)\n",
    "        # 아래는 인자로 입력된 yolo객체의 detect_image()로 변환한다.\n",
    "        detected_image = model.detect_image(image)\n",
    "        # cv2의 video writer로 출력하기 위해 다시 PIL의 Image형태를 array형태로 변환 \n",
    "        result = np.asarray(detected_image)\n",
    "        index +=1\n",
    "        print('#### frame:{0} 이미지 처리시간:{1}'.format(index, round(time.time()-start,3)))\n",
    "        \n",
    "        vid_writer.write(result)\n",
    "    \n",
    "    vid_writer.release()\n",
    "    cap.release()\n",
    "    print('### Video Detect 총 수행시간:', round(time.time()-start, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_video_yolo(ballnfish_yolo, '../../data/video/NFL01.mp4', '../../data/output/NFL_yolo_01.avi')\n",
    "!gsutil cp ../../data/output/NFL_yolo_01.avi gs://my_bucket_dlcv/data/output/NFL_yolo_01.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_video_yolo(ballnfish_yolo, '../../data/video/FishnShark01.mp4', '../../data/output/FishnShark_yolo_01.avi')\n",
    "!gsutil cp ../../data/output/FishnShark_yolo_01.avi gs://my_bucket_dlcv/data/output/FishnShark_yolo_01.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf113] *",
   "language": "python",
   "name": "conda-env-tf113-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

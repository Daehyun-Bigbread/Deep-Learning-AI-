{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kaggle에서 2018 Data science bowl Nucleus segmentation 데이터를 download 한 뒤 ./nucleus_data 디렉토리에 압축을 품\n",
    "# stage1_train.zip 파일에 train용 image 데이터와 mask 데이터가 있음. stage1_train_zip 파일을 stage1_train 디렉토리에 압축 해제\n",
    "# unzip stage1_train.zip -d stage1_train\n",
    "# stage1_test.zip 파일에 test용 image 데이터와 mask 데이터가 있음. stage1_test_zip 파일을 stage1_test 디렉토리에 압축 해제\n",
    "# unzip stage1_test.zip -d stage1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train용 데이터 세트에 들어있는 데이터 구조 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "HOME_DIR = str(Path.home())\n",
    "\n",
    "# 학습용, 테스트용 모두의 기준 디렉토리는 ~/DLCV/data/nucleus 임. \n",
    "DATASET_DIR = os.path.join(HOME_DIR, \"DLCV/data/nucleus\")\n",
    "print(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~/DLCV/data/nucleus 디렉토리 밑에 학습용 디렉토리인 stage1_train이 만들어짐.stage1_train에 학습 이미지, mask 이미지 데이터 존재. \n",
    "subset_dir = 'stage1_train'\n",
    "train_dataset_dir = os.path.join(DATASET_DIR, subset_dir)\n",
    "print(train_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터 세트의 이미지 파일, mask 파일이 어떠한 디렉토리 구조 형태로 저장되어 있는지 확인. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 별로 고유한 이미지명을 가지는 이미지 디렉토리를 가지고 이 디렉토리에 하위 디렉토리로 images, masks를 가짐\n",
    "# images 에는 하나의 이미지가 있으며 masks는 여러개의 mask 이미지 파일을 가지고 있음. 즉 하나의 이미지에 여러개의 mask 파일을 가지고 있는 형태임. \n",
    "# next(os.walk(directory))[1]은 sub directory를 iteration으로 반환 next(os.walk(directory))[2]는 해당 디렉토리 밑에 파일들을 iteration으로 반환\n",
    "index = 0 \n",
    "for dir in next(os.walk(train_dataset_dir))[1]:\n",
    "    print('',dir)\n",
    "    subdirs = os.path.join(train_dataset_dir, dir)\n",
    "    for subdir in next(os.walk(subdirs))[1]:\n",
    "        print('----'+subdir)\n",
    "        sub_subdirs = os.path.join(subdirs, subdir)\n",
    "        for sub_subdir in next(os.walk(sub_subdirs))[2]:\n",
    "            print('    ---- '+sub_subdir)\n",
    "            index += 1\n",
    "            if index >1000:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 학습시 사용할 임의의 Validation용 IMAGE ID를 별도로 선정. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "def get_valid_image_ids(dataset_dir, valid_size):\n",
    "    \n",
    "    dataset_dir = os.path.join(dataset_dir,'stage1_train')\n",
    "    image_ids = next(os.walk(dataset_dir))[1]\n",
    "    total_cnt = len(image_ids)\n",
    "    \n",
    "    valid_cnt = int(total_cnt * valid_size)\n",
    "    valid_indexes = np.random.choice(total_cnt, valid_cnt, replace=False)\n",
    "    \n",
    "    return list(np.array(image_ids)[valid_indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_valid_image_ids(DATASET_DIR, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset객체의 add_image()를 이용하여 개별 이미지를 Dataset 객체로 로딩하는 load_nucleus() 함수 생성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn import utils\n",
    "import skimage\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "VAL_IMAGE_IDS = get_valid_image_ids(DATASET_DIR, 0.1)\n",
    "\n",
    "class NucleusDataset(utils.Dataset):\n",
    "    \n",
    "    # subset은 train, valid, stage1_test, stage2_test\n",
    "    def load_nucleus(self, dataset_dir, subset):\n",
    "        self.add_class(source='nucleus', class_id=1, class_name='nucleus')\n",
    "        \n",
    "        subset_dir = 'stage1_train' if subset in ['train', 'val'] else subset\n",
    "        dataset_dir = os.path.join(dataset_dir, subset_dir)\n",
    "        \n",
    "        if subset=='val':\n",
    "            image_ids = VAL_IMAGE_IDS\n",
    "        else:\n",
    "            image_ids = next(os.walk(dataset_dir))[1]\n",
    "            if subset=='train':\n",
    "                image_ids = list(set(image_ids) - set(VAL_IMAGE_IDS))\n",
    "\n",
    "        for image_id in image_ids:       \n",
    "            self.add_image('nucleus', image_id=image_id, path=os.path.join(dataset_dir, image_id, 'images/{}.png'.format(image_id)))\n",
    "    \n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), 'masks')\n",
    "        mask_list=[]\n",
    "        for mask_file in next(os.walk(mask_dir))[2]:\n",
    "            if mask_file.endswith('.png'):\n",
    "                mask = skimage.io.imread(os.path.join(mask_dir, mask_file)).astype(np.bool)\n",
    "                mask_list.append(mask)\n",
    "                \n",
    "        masks = np.stack(mask_list, axis=-1)\n",
    "        \n",
    "        return masks, np.ones([masks.shape[-1]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleus_dataset = NucleusDataset(utils.Dataset)\n",
    "nucleus_dataset.load_nucleus(DATASET_DIR, 'train')\n",
    "#print('class info:', nucleus_dataset.class_info)\n",
    "#print('image info:', nucleus_dataset.image_info)\n",
    "nucleus_dataset.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('class id:', nucleus_dataset.class_ids)\n",
    "print('image id:', nucleus_dataset._image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleus_dataset.image_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, class_ids = nucleus_dataset.load_mask(0)\n",
    "masks.shape, class_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, class_ids = nucleus_dataset.load_mask(0)\n",
    "\n",
    "sample_img = skimage.io.imread(os.path.join(DATASET_DIR, 'stage1_train', \n",
    "                        'df53d0b6c2c4e45d759b2c474011e2b2b32552cd100ca4b22388ab9ca1750ee2',\n",
    "                        'images',\n",
    "                        'df53d0b6c2c4e45d759b2c474011e2b2b32552cd100ca4b22388ab9ca1750ee2.png'))\n",
    "print('image shape:', sample_img.shape)\n",
    "plt.imshow(sample_img)\n",
    "plt.show()\n",
    "\n",
    "print(masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "image_ids = np.random.choice(nucleus_dataset.image_ids, 4)\n",
    "print(image_ids)\n",
    "for image_id in image_ids:\n",
    "    image = nucleus_dataset.load_image(image_id)\n",
    "    mask, class_ids = nucleus_dataset.load_mask(image_id)\n",
    "    print('mask shape:', mask.shape, 'class_ids shape:', class_ids.shape)\n",
    "    visualize.display_top_masks(image, mask, class_ids, nucleus_dataset.class_names, limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nucleus 데이터 세트 Train/Inference \n",
    "* Matterport 패키지에서 사용될 수 있도록 학습/검증/테스트 데이터 세트를 변환하여 생성 필요\n",
    "* 학습 또는 Inference를 위한 Config 설정.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = NucleusDataset()\n",
    "dataset_train.load_nucleus(DATASET_DIR, 'train')\n",
    "# dataset을 load한 뒤에는 반드시 prepare()메소드를 호출\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = NucleusDataset()\n",
    "dataset_val.load_nucleus(DATASET_DIR, \"val\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_train.image_info), len(dataset_val.image_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nucleus 학습을 위한 새로운 Config 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "\n",
    "train_image_cnt = len(dataset_train.image_info)\n",
    "val_image_cnt = len(dataset_val.image_info)\n",
    "print('train_image_cnt:',train_image_cnt, 'validation image count:',val_image_cnt)\n",
    "\n",
    "class NucleusConfig(Config):\n",
    "    \"\"\"Configuration for training on the nucleus segmentation dataset.\"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"nucleus\"\n",
    "\n",
    "    # Adjust depending on your GPU memory\n",
    "    IMAGES_PER_GPU = 6\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + nucleus\n",
    "\n",
    "    # Number of training and validation steps per epoch\n",
    "    STEPS_PER_EPOCH = (train_image_cnt) // IMAGES_PER_GPU\n",
    "    VALIDATION_STEPS = max(1, (val_image_cnt // IMAGES_PER_GPU))\n",
    "\n",
    "    # Don't exclude based on confidence. Since we have two classes\n",
    "    # then 0.5 is the minimum anyway as it picks between nucleus and BG\n",
    "    DETECTION_MIN_CONFIDENCE = 0\n",
    "\n",
    "    # Backbone network architecture\n",
    "    # Supported values are: resnet50, resnet101\n",
    "    BACKBONE = \"resnet50\"\n",
    "\n",
    "    # Input image resizing\n",
    "    # Random crops of size 512x512\n",
    "    IMAGE_RESIZE_MODE = \"crop\"\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    IMAGE_MIN_SCALE = 2.0\n",
    "\n",
    "    # Length of square anchor side in pixels\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
    "\n",
    "    # ROIs kept after non-maximum supression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 1000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "\n",
    "    # How many anchors per image to use for RPN training\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 64\n",
    "\n",
    "    # Image mean (RGB)\n",
    "    MEAN_PIXEL = np.array([43.53, 39.56, 48.22])\n",
    "\n",
    "    # If enabled, resizes instance masks to a smaller size to reduce\n",
    "    # memory load. Recommended when using high-resolution images.\n",
    "    USE_MINI_MASK = True\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "\n",
    "    # Number of ROIs per image to feed to classifier/mask heads\n",
    "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
    "    # enough positive proposals to fill this and keep a positive:negative\n",
    "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
    "    # the RPN NMS threshold.\n",
    "    TRAIN_ROIS_PER_IMAGE = 128\n",
    "\n",
    "    # Maximum number of ground truth instances to use in one image\n",
    "    MAX_GT_INSTANCES = 200\n",
    "\n",
    "    # Max number of final detections per image\n",
    "    DETECTION_MAX_INSTANCES = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coco  pretrained된 가중치 모델 위치 지정. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"./pretrained/mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"./snapshots/nucleus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습을 위한 모델을 생성, Mask_RCNN 패키지는 modellib에 MaskRCNN 객체를 이용하여 Mask RCNN 모델을 생성함. \n",
    "\n",
    "생성 인자\n",
    "* mode: training인지 inference인지 설정\n",
    "* config: training 또는 inference에 따라 다른 config 객체 사용. Config객체를 상속 받아 각 경우에 새로운 객체를 만들고 이를 이용. \n",
    "inference 시에는 Image를 하나씩 입력 받아야 하므로 Batch size를 1로 만들 수 있도록 설정 \n",
    "            \n",
    "* model_dir: 학습 진행 중에 Weight 모델이 저장되는 장소 지정.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn import model as modellib\n",
    "\n",
    "train_config = NucleusConfig()\n",
    "train_config.display()\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=train_config,\n",
    "                                  model_dir=MODEL_DIR)\n",
    "\n",
    "# Exclude the last layers because they require a matching\n",
    "# number of classes\n",
    "model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 데이터 세트와 검증 데이터 세트를 NucleusDataset 객체에 로드하고 train 시작\n",
    "* augmentation은 imgaug를 사용. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "\n",
    "img_aug = iaa.SomeOf((0, 2), [\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.OneOf([iaa.Affine(rotate=90),\n",
    "                   iaa.Affine(rotate=180),\n",
    "                   iaa.Affine(rotate=270)]),\n",
    "        iaa.Multiply((0.8, 1.5)),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 5.0))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Train all layers\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=train_config.LEARNING_RATE,\n",
    "            epochs=40, augmentation=img_aug,\n",
    "            layers='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 모델을 이용하여 Inference 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 예측용 모델을 로드. mode는 inference로 설정,config는 NucleusInferenceConfig()로 설정,\n",
    "## 예측용 모델에 위에서 찾은 학습 중 마지막 저장된 weight파일을 로딩함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NucleusInferenceConfig(NucleusConfig):\n",
    "    NAME='nucleus'\n",
    "    # 이미지 한개씩 차례로 inference하므로 batch size를 1로 해야 하며 이를 위해 IMAGES_PER_GPU = 1\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # pad64는 64 scale로 이미지를 맞춰서 resize수행. \n",
    "    IMAGE_RESIZE_MODE = \"pad64\"\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_config = NucleusInferenceConfig()\n",
    "inference_model = modellib.MaskRCNN(mode=\"inference\", config=infer_config, model_dir=MODEL_DIR)\n",
    "weights_path = model.find_last()\n",
    "print('학습중 마지막으로 저장된 weight 파일:', weights_path)\n",
    "inference_model.load_weights(weights_path, by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 테스트용 데이터 세트를 NucleusDataset으로 로딩. load_nucleus() 테스트 세트를 지정하는 'stage1_test'를 입력. \n",
    "dataset_test = NucleusDataset()\n",
    "dataset_test.load_nucleus(DATASET_DIR, 'stage1_test')\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test.image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### mask detected 된 임의의 파일을 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id in dataset_test.image_ids:\n",
    "        # Load image and run detection\n",
    "        image = dataset_test.load_image(image_id)\n",
    "        print(len(image))\n",
    "        # Detect objects\n",
    "        r = inference_model.detect([image], verbose=0)[0]\n",
    "        # Save image with masks\n",
    "        visualize.display_instances(\n",
    "            image, r['rois'], r['masks'], r['class_ids'],\n",
    "            dataset_test.class_names, r['scores'],\n",
    "            show_bbox=False, show_mask=False,\n",
    "            title=\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id in dataset_test.image_ids:\n",
    "        # Load image and run detection\n",
    "        image = dataset_test.load_image(image_id)\n",
    "        print(len(image))\n",
    "       \n",
    "        #plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(model, args.dataset, args.subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(model, dataset_dir, subset):\n",
    "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
    "    print(\"Running on {}\".format(dataset_dir))\n",
    "\n",
    "    # Create directory\n",
    "    if not os.path.exists(RESULTS_DIR):\n",
    "        os.makedirs(RESULTS_DIR)\n",
    "    submit_dir = \"submit_{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
    "    submit_dir = os.path.join(RESULTS_DIR, submit_dir)\n",
    "    os.makedirs(submit_dir)\n",
    "\n",
    "    # Read dataset\n",
    "    dataset = NucleusDataset()\n",
    "    dataset.load_nucleus(dataset_dir, subset)\n",
    "    dataset.prepare()\n",
    "    # Load over images\n",
    "    submission = []\n",
    "    for image_id in dataset.image_ids:\n",
    "        # Load image and run detection\n",
    "        image = dataset.load_image(image_id)\n",
    "        # Detect objects\n",
    "        r = model.detect([image], verbose=0)[0]\n",
    "        # Encode image to RLE. Returns a string of multiple lines\n",
    "        source_id = dataset.image_info[image_id][\"id\"]\n",
    "        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
    "        submission.append(rle)\n",
    "        # Save image with masks\n",
    "        visualize.display_instances(\n",
    "            image, r['rois'], r['masks'], r['class_ids'],\n",
    "            dataset.class_names, r['scores'],\n",
    "            show_bbox=False, show_mask=False,\n",
    "            title=\"Predictions\")\n",
    "        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n",
    "\n",
    "    # Save to csv file\n",
    "    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n",
    "    file_path = os.path.join(submit_dir, \"submit.csv\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(submission)\n",
    "    print(\"Saved to \", submit_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf113] *",
   "language": "python",
   "name": "conda-env-tf113-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

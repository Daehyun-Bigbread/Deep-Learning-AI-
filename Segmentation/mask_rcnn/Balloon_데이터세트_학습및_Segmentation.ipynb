{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matterport 패키지를 이용하여 Balloon 데이터 세트를 학습하고 이를 기반으로 Segmentation 적용\n",
    "* Matterport 패키지의 학습 프로세스를 상세히 설명."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주요 수행 모듈인 balloon 모듈을 setup 하여 import하지 않고, 소스코드에서 바로 import 수행.\n",
    "##### 이를 위해 PATH에 balloon.py 파일이 있는 디렉토리를 지정하고 import 를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask_RCNN 패키지의 samples/balloon 디렉토리의 balloon.py 를 import 한다. \n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"Mask_RCNN/samples/balloon/\"))\n",
    "\n",
    "import balloon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### balloon 모듈은 어떠한 API들로 구성되어 있는지 직접 소스코드에서 확인. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"./Mask_RCNN/samples/balloon/balloon.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### balloon 데이터 세트가 제대로 되어 있는지 확인.  train과 val 서브 디렉토리가 ./Mask_RCNN/dataset/balloon 에 존재해야 함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "HOME_DIR = str(Path.home())\n",
    "BALLOON_DATA_DIR = os.path.join(HOME_DIR, \"DLCV/data/balloon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### balloon 모듈에 설정된 Config 셋업. GPU 갯수, Batch시 image갯수가 사전 설정 되어 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = balloon.BalloonConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### balloon 모듈에서 balloon 데이터 세트 로딩. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset 로딩한다. . \n",
    "\n",
    "dataset = balloon.BalloonDataset()\n",
    "dataset.load_balloon(BALLOON_DATA_DIR, \"train\")\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset.num_classes))\n",
    "for i, info in enumerate(dataset.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### balloon 모듈에서 로딩한 balloon 데이터 세트의 세부 정보 확인. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset의 image_info는 리스트 객체이며 내부 원소로 이미지별 세부 정보를 딕셔너리로 가지고 있음. \n",
    "# dataset의 image_ids 는 이미지의 고유 id나 이름이 아니라 dataset에서 이미지의 상세 정보를 관리하기 위한 리스트 인덱스에 불과 \n",
    "\n",
    "print('#### balloon 데이터 세트 이미지의 인덱스 ID들 ####')\n",
    "print(dataset.image_ids)\n",
    "print('\\n ##### balloon 데이터 세트의 이미지 정보들 ####')\n",
    "print(dataset.image_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### polygon 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_28 = dataset.image_info[28]\n",
    "polygons = image_28['polygons']\n",
    "polygon_x = polygons[0]['all_points_x']\n",
    "polygon_y = polygons[0]['all_points_y']\n",
    "print(len(polygon_x))\n",
    "print('polygon_x:', polygon_x, 'polygon_y:',polygon_y)\n",
    "\n",
    "polygon_xy = [(x, y) for (x, y) in zip(polygon_x, polygon_y)]\n",
    "print('polygon_xy:', polygon_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_28_array = cv2.imread(os.path.join(BALLOON_DATA_DIR,'train/'+image_28['id']))\n",
    "for position in polygon_xy:\n",
    "    cv2.circle(image_28_array, position, 3, (255, 0, 0), -1)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis('off')    \n",
    "plt.imshow(image_28_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(99)\n",
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset.image_ids, 4)\n",
    "print('image_ids:', image_ids)\n",
    "for image_id in image_ids:\n",
    "    image = dataset.load_image(image_id)\n",
    "    # 지정된 image_id에 있는 mask 를 로딩하고 시각화를 위한 mask정보들과 대상 클래스 ID들을 추출\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    #원본 데이터와 여러개의 클래스들에 대해 Mask를 시각화 하되, 가장 top 클래스에 대해서는 클래스명까지 추출. 나머지는 배경\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = dataset.load_image(28)\n",
    "print(image.shape)\n",
    "print(image_28['polygons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### polygon 형태의 데이터를 boolean mask 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "img = np.zeros((10, 10), dtype=np.uint8)\n",
    "r = np.array([1, 2, 8])\n",
    "c = np.array([1, 7, 4])\n",
    "print('img:', img)\n",
    "# r과 c로 지정된 인덱스에 있는 img 값만 1로 설정함. \n",
    "rr, cc = skimage.draw.polygon(r, c)\n",
    "img[rr, cc] = 1\n",
    "print('row positions:',rr, 'column positions:',cc)\n",
    "print('0, 1로 masking된 img:\\n',img)\n",
    "print('Boolean형태로 masking된 img:\\n',img.astype(np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, class_ids = dataset.load_mask(28)\n",
    "print(\"mask shape:\", mask.shape, \"class_ids:\", class_ids)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = dataset.load_image(28)\n",
    "mask, class_ids = dataset.load_mask(28)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ballon 데이터 세트의 image정보, 클래스 정보, mask 정보의 추출과 변환을 위한 BallonDataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalloonDataset(utils.Dataset):\n",
    "\n",
    "    def load_balloon(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the Balloon dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        # 클래스 id와 클래스명 등록은 Dataset의 add_class()를 이용. \n",
    "        self.add_class(\"balloon\", 1, \"balloon\")\n",
    "\n",
    "        # train또는 val 용도의 Dataset 생성만 가능. \n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "        \n",
    "        # json 형태의 annotation을 로드하고 파싱. \n",
    "        annotations = json.load(open(os.path.join(dataset_dir, \"via_region_data.json\")))\n",
    "        annotations = list(annotations.values())  # don't need the dict keys\n",
    "        \n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            # Get the x, y coordinaets of points of the polygons that make up\n",
    "            # the outline of each object instance. These are stores in the\n",
    "            # shape_attributes (see json format above)\n",
    "            # The if condition is needed to support VIA versions 1.x and 2.x.\n",
    "            if type(a['regions']) is dict:\n",
    "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
    "            else:\n",
    "                polygons = [r['shape_attributes'] for r in a['regions']] \n",
    "\n",
    "            # load_mask() needs the image size to convert polygons to masks.\n",
    "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
    "            # the image. This is only managable since the dataset is tiny.\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"balloon\",\n",
    "                image_id=a['filename'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a balloon dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"balloon\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "    \n",
    "    '''def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"balloon\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = json.load(open(os.path.join(BALLOON_DATA_DIR, \"train/via_region_data.json\")))\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = list(annotations.values())\n",
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balloon 데이터 세트의 학습 수행. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습과 Validation용 Dataset 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "# Training dataset.\n",
    "dataset_train = BalloonDataset()\n",
    "dataset_train.load_balloon(BALLOON_DATA_DIR, \"train\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = BalloonDataset()\n",
    "dataset_val.load_balloon(BALLOON_DATA_DIR, \"val\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "\n",
    "TRAIN_IMAGE_CNT = len(dataset_train.image_info)\n",
    "VALID_IMAGE_CNT = len(dataset_val.image_info)\n",
    "\n",
    "class BalloonConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"balloon\"\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + balloon\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    \n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "    \n",
    "    # 추가.\n",
    "    GPU_COUNT = 1\n",
    "\n",
    "    # 원본에서 수정.\n",
    "    #STEPS_PER_EPOCH = TRAIN_IMAGE_CNT  // IMAGES_PER_GPU\n",
    "    #VALIDATION_STEPS = VALID_IMAGE_CNT  // IMAGES_PER_GPU\n",
    "    \n",
    "    # 원본 STEPS_PER_EPOCH\n",
    "    STEPS_PER_EPOCH = TRAIN_IMAGE_CNT  // IMAGES_PER_GPU\n",
    "    VALIDATION_STEPS = VALID_IMAGE_CNT  // IMAGES_PER_GPU\n",
    "\n",
    "    #BACKBONE = 'resnet101'\n",
    "    \n",
    "# config 설정. \n",
    "train_config = BalloonConfig()\n",
    "train_config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기반 Mask RCNN Training 모델 생성 및 초기 weight값 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "balloon_model = modellib.MaskRCNN(mode=\"training\", config=train_config, model_dir='./snapshots')\n",
    "\n",
    "# COCO 데이터 세트로 pretrained 된 모델을 이용하여 초기 weight값 로딩. \n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"./pretrained/mask_rcnn_coco.h5\")\n",
    "balloon_model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "데이터 세트가 작고,단 하나의 클래스임. \n",
    "pretrained 된 Coco 데이터 세트로 초기 weight 설정되었기에 RPN과 classifier만 학습해도 모델 성능은 큰 영향이 없을 거라 예상\n",
    "all: All the layers\n",
    "3+: Train Resnet stage 3 and up\n",
    "4+: Train Resnet stage 4 and up\n",
    "5+: Train Resnet stage 5 and up\n",
    "'''\n",
    "print(\"Training network heads\")\n",
    "balloon_model.train(dataset_train, dataset_val,\n",
    "            learning_rate=train_config.LEARNING_RATE,\n",
    "            epochs=30,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습이 완료된 모델을 이용하여 inference 수행. \n",
    "#### config를 inference용으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(BalloonConfig):\n",
    "    # NAME은 학습모델과 동일한 명을 부여\n",
    "    NAME='balloon'\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "        \n",
    "infer_config = InferenceConfig()\n",
    "infer_config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습된 모델의 weight 파일을 MaskRCNN의 inference 모델로 로딩. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir='./snapshots', config=infer_config)\n",
    "# callback에 의해 model weights 가 파일로 생성되며, 가장 마지막에 생성된 weights 가 가장 적은 loss를 가지는 것으로 가정. \n",
    "weights_path = model.find_last()\n",
    "print('model path:', weights_path)\n",
    "# 지정된 weight 파일명으로 모델에 로딩. \n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instance Segmentation을 수행할 파일들을 dataset로 로딩. val 디렉토리에 있는 파일들을 로딩. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference를 위해 val Dataset 재로딩. \n",
    "dataset_val = BalloonDataset()\n",
    "dataset_val.load_balloon(BALLOON_DATA_DIR, \"val\")\n",
    "dataset_val.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset_val.image_ids), dataset_val.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn import model as modellib\n",
    "\n",
    "# dataset중에 임의의 파일을 한개 선택. \n",
    "#image_id = np.random.choice(dataset.image_ids)\n",
    "image_id = 5\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask=modellib.load_image_gt(dataset_val, infer_config, image_id, use_mini_mask=False)\n",
    "info = dataset_val.image_info[image_id]\n",
    "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
    "                                       dataset_val.image_reference(image_id)))\n",
    "\n",
    "# Run object detection\n",
    "results = model.detect([image], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], \n",
    "                            title=\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask_RCNN 패키지의 samples/balloon 디렉토리의 balloon.py 를 import 한다. \n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"Mask_RCNN/samples/balloon/\"))\n",
    "\n",
    "import balloon\n",
    "from mrcnn.visualize import display_images\n",
    "\n",
    "splash = balloon.color_splash(image, r['masks'])\n",
    "display_images([splash], cols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_splash(image, mask):\n",
    "    \"\"\"Apply color splash effect.\n",
    "    image: RGB image [height, width, 3]\n",
    "    mask: instance segmentation mask [height, width, instance count]\n",
    "    Returns result image.\n",
    "    \"\"\"\n",
    "    # Make a grayscale copy of the image. The grayscale copy still\n",
    "    # has 3 RGB channels, though.\n",
    "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
    "    # Copy color pixels from the original color image where mask is set\n",
    "    if mask.shape[-1] > 0:\n",
    "        # We're treating all instances as one, so collapse the mask into one layer\n",
    "        mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
    "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
    "    else:\n",
    "        splash = gray.astype(np.uint8)\n",
    "    return splash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 변수 shape debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('image shape:',image.shape, 'r mask shape:',r['masks'].shape)\n",
    "mask = (np.sum(r['masks'], -1, keepdims=True) >= 1)\n",
    "print('sum mask shape:',mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.sum() 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((10, 10, 3))\n",
    "#print(a)\n",
    "#print(np.sum(a))\n",
    "print(np.sum(a, axis=-1).shape)\n",
    "print(np.sum(a, -1, keepdims=True).shape)\n",
    "print(np.sum(a, -1, keepdims=True) >=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.where() 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = (np.sum(a, -1, keepdims=True) >=1)\n",
    "print(test_mask.shape)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        test_mask[i, j, 0] = False\n",
    "        \n",
    "test_image = np.ones((10, 10, 3))\n",
    "test_gray = np.zeros((10, 10, 3))\n",
    "np.where(test_mask, test_image, test_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video에 color splash를 적용. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, Video, HTML\n",
    "Video('../../data/video/balloon_dog02.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video color splash를 적용한 함수를 생성하고 이를 이용해 video color splash 수행. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "def detect_video_color_splash(model, video_input_path=None, video_output_path=None):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_input_path)\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "    vid_writer = cv2.VideoWriter(video_output_path, codec, fps, (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                                                                 round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"총 Frame 개수: {0:}\".format(total))\n",
    "\n",
    "    frame_index = 0\n",
    "    success = True\n",
    "    while True:\n",
    "        \n",
    "        hasFrame, image_frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            print('End of frame')\n",
    "            break\n",
    "        frame_index += 1\n",
    "        print(\"frame index:{0:}\".format(frame_index), end=\" \")\n",
    "        \n",
    "        # OpenCV returns images as BGR, convert to RGB\n",
    "        image_frame = image_frame[..., ::-1]\n",
    "        start=time.time()\n",
    "        # Detect objects\n",
    "        r = model.detect([image_frame], verbose=0)[0]\n",
    "        print('detected time:', time.time()-start)\n",
    "        # Color splash\n",
    "        splash = color_splash(image_frame, r['masks'])\n",
    "        # RGB -> BGR to save image to video\n",
    "        splash = splash[..., ::-1]\n",
    "        # Add image to video writer\n",
    "        vid_writer.write(splash)\n",
    "    \n",
    "    vid_writer.release()\n",
    "    cap.release()       \n",
    "    \n",
    "    print(\"Saved to \", video_output_path)\n",
    "    \n",
    "detect_video_color_splash(model, video_input_path='../../data/video/balloon_dog02.mp4', \n",
    "                          video_output_path='../../data/output/balloon_dog02_output.avi')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 생성된 Output 파일을 Object Storage에 저장한 뒤 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp ../../data/output/balloon_dog02_output.avi gs://my_bucket_dlcv/data/output/balloon_dog02_output.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf113] *",
   "language": "python",
   "name": "conda-env-tf113-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matterport 패키지를 이용하여 pretrained coco 모델을 로딩 후 단일 이미지와 영상 Segmentation 수행. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matterport로 pretrained된 coco weight 모델을 다운로드함(최초시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn import utils\n",
    "\n",
    "ROOT_DIR = os.path.abspath('.')\n",
    "\n",
    "# 최초에는 coco pretrained 모델을 다운로드함. \n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"./pretrained/mask_rcnn_coco.h5\")\n",
    "\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ~/DLCV/Segmentation/mask_rcnn/pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MASK RCNN 모델을 위한 Config 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "\n",
    "infer_config = Config()\n",
    "infer_config.BATCH_SIZE=4\n",
    "infer_config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config 클래스를 상속받아서 사용\n",
    "from mrcnn.config import Config\n",
    "\n",
    "#환경 변수는 모두 대문자 \n",
    "class InferenceConfig(Config):\n",
    "    # inference시에는 batch size를 1로 설정. 그리고 IMAGES_PER_GPU도 1로 설정. \n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # NAME은 반드시 주어야 한다. \n",
    "    NAME='coco_infer'\n",
    "    NUM_CLASSES=81\n",
    "    \n",
    "\n",
    "infer_config = InferenceConfig()\n",
    "infer_config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COCO ID와 클래스명 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matterport는 0을 Background로, 1부터 80까지 coco dataset 클래스 id/클래스 명 매핑. \n",
    "labels_to_names = {0:'BG',1: 'person',2: 'bicycle',3: 'car',4: 'motorbike',5: 'aeroplane',6: 'bus',7: 'train',8: 'truck',9: 'boat',10: 'traffic light',\n",
    "                   11: 'fire hydrant',12: 'stop sign',13: 'parking meter',14: 'bench',15: 'bird',16: 'cat',17: 'dog',18: 'horse',19: 'sheep',20: 'cow',\n",
    "                   21: 'elephant',22: 'bear',23: 'zebra',24: 'giraffe',25: 'backpack',26: 'umbrella',27: 'handbag',28: 'tie',29: 'suitcase',30: 'frisbee',\n",
    "                   31: 'skis',32: 'snowboard',33: 'sports ball',34: 'kite',35: 'baseball bat',36: 'baseball glove',37: 'skateboard',38: 'surfboard',39: 'tennis racket',40: 'bottle',\n",
    "                   41: 'wine glass',42: 'cup',43: 'fork',44: 'knife',45: 'spoon',46: 'bowl',47: 'banana',48: 'apple',49: 'sandwich',50: 'orange',\n",
    "                   51: 'broccoli',52: 'carrot',53: 'hot dog',54: 'pizza',55: 'donut',56: 'cake',57: 'chair',58: 'sofa',59: 'pottedplant',60: 'bed',\n",
    "                   61: 'diningtable',62: 'toilet',63: 'tvmonitor',64: 'laptop',65: 'mouse',66: 'remote', 67: 'keyboard',68: 'cell phone',69: 'microwave',70: 'oven',\n",
    "                   71: 'toaster',72: 'sink',73: 'refrigerator',74: 'book',75: 'clock',76: 'vase',77: 'scissors',78: 'teddy bear',79: 'hair drier',80: 'toothbrush' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MS-COCO 기반으로 Pretrained 된 모델을 로딩\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR,'snapshots') \n",
    "print(MODEL_DIR)\n",
    "model = modellib.MaskRCNN(mode=\"inference\",  model_dir=MODEL_DIR, config=infer_config)\n",
    "\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "beatles_img = cv2.imread('../../data/image/beatles01.jpg')\n",
    "# matterport는 내부적으로 image처리를 위해 skimage를 이용하므로 BGR2RGB처리함. \n",
    "beatles_img_rgb = cv2.cvtColor(beatles_img, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "results = model.detect([beatles_img_rgb], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results), results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[0]['masks']는 object 별로 mask가 전체 이미지에 대해서 layered된 image 배열을 가지고 있음.  \n",
    "results[0]['rois'].shape, results[0]['scores'].shape, results[0]['class_ids'].shape, results[0]['masks'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn import visualize\n",
    "\n",
    "r = results[0]\n",
    "class_names = [value for value in labels_to_names.values()]\n",
    "visualize.display_instances(beatles_img_rgb, r['rois'], r['masks'], r['class_ids'], \n",
    "                            class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "wick_img = cv2.imread('../../data/image/john_wick01.jpg')\n",
    "wick_img_rgb = cv2.cvtColor(wick_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def get_segment_result(img_array_list, verbose):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = model.detect(img_array_list, verbose=1)\n",
    "    \n",
    "    if verbose==1:\n",
    "        print('## inference time:{0:}'.format(time.time()-start_time))\n",
    "    \n",
    "    return results\n",
    "\n",
    "r = get_segment_result([wick_img_rgb], verbose=1)[0]\n",
    "visualize.display_instances(wick_img_rgb, r['rois'], r['masks'], r['class_ids'], \n",
    "                            class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video에 Segmentation 적용 \n",
    "* MaskRCNN 패키지는 visualize.display_instances() 함수내부에서 matplotlib를 이용하여 자체 시각화를 수행. \n",
    "* Video segment instance에 적용하기 위해서 bounding box와 instance masking을 적용하는 별도의 함수 생성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.visualize import *\n",
    "import cv2\n",
    "\n",
    "def get_segmented_image(img_array, boxes, masks, class_ids, class_names,\n",
    "                      scores=None, show_mask=True, show_bbox=True, colors=None, captions=None):\n",
    "   \n",
    "    # Number of instances\n",
    "    N = boxes.shape[0]\n",
    "    if not N:\n",
    "        print(\"\\n*** No instances to display *** \\n\")\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "    \n",
    "\n",
    "    # Generate random colors\n",
    "    colors = colors or random_colors(N)\n",
    "\n",
    "    # Show area outside image boundaries.\n",
    "    height, width = img_array.shape[:2]\n",
    "\n",
    "    masked_image = img_array.astype(np.uint32).copy()\n",
    "\n",
    "    for i in range(N):\n",
    "        color = np.array(colors[i])*255\n",
    "        color = color.tolist()\n",
    "\n",
    "        # Bounding box\n",
    "        if not np.any(boxes[i]):\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "            continue\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        \n",
    "        if show_bbox:\n",
    "            cv2.rectangle(img_array, (x1, y1), (x2, y2), color, thickness=1 )\n",
    "\n",
    "        # Label\n",
    "        if not captions:\n",
    "            class_id = class_ids[i]\n",
    "            score = scores[i] if scores is not None else None\n",
    "            label = class_names[class_id]\n",
    "            caption = \"{} {:.3f}\".format(label, score) if score else label\n",
    "        else:\n",
    "            caption = captions[i]\n",
    "            \n",
    "        cv2.putText(img_array, caption, (x1, y1+8), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), thickness=1)\n",
    "        \n",
    "        # Mask\n",
    "        # 클래스별 mask 정보를 추출 \n",
    "        mask = masks[:, :, i]\n",
    "        if show_mask:\n",
    "            # visualize 모듈의 apply_mask()를 적용하여 masking 수행.\n",
    "            img_array = apply_mask(img_array, mask, color)\n",
    "            \n",
    "            # mask에 contour 적용. \n",
    "            padded_mask = np.zeros(\n",
    "                            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
    "            padded_mask[1:-1, 1:-1] = mask\n",
    "            contours = find_contours(padded_mask, 0.5)\n",
    "            for verts in contours:\n",
    "                # padding 제거. 아래에서 verts를 32bit integer로 변경해야 polylines()에서 오류 발생하지 않음. \n",
    "                verts = verts.astype(np.int32)\n",
    "                #x, y 좌표 교체\n",
    "                verts = np.fliplr(verts) - 1\n",
    "                cv2.polylines(img_array, [verts], True, color, thickness=1)\n",
    "    \n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  단일 IMAGE에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "wick_img = cv2.imread('../../data/image/john_wick01.jpg')\n",
    "wick_img_rgb = cv2.cvtColor(wick_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "r = get_segment_result([wick_img_rgb], verbose=1)[0]\n",
    "segmented_img = get_segmented_image(wick_img_rgb, r['rois'], r['masks'], r['class_ids'], \n",
    "                                    class_names, r['scores'])\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.imshow(segmented_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video Segmentation 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "video_input_path = '../../data/video/John_Wick_small.mp4'\n",
    "# video output 의 포맷은 avi 로 반드시 설정 필요. \n",
    "video_output_path = '../../data/output/John_Wick_small_matterport01.avi'\n",
    "\n",
    "cap = cv2.VideoCapture(video_input_path)\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "vid_writer = cv2.VideoWriter(video_output_path, codec, fps, (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"총 Frame 개수: {0:}\".format(total))\n",
    "\n",
    "frame_index = 0\n",
    "while True:\n",
    "    \n",
    "    hasFrame, image_frame = cap.read()\n",
    "    if not hasFrame:\n",
    "        print('End of frame')\n",
    "        break\n",
    "    \n",
    "    frame_index += 1\n",
    "    print(\"frame index:{0:}\".format(frame_index), end=\" \")\n",
    "    r = get_segment_result([image_frame], verbose=1)[0]\n",
    "    segmented_img = get_segmented_image(image_frame, r['rois'], r['masks'], r['class_ids'], \n",
    "                                    class_names, r['scores'])\n",
    "    vid_writer.write(segmented_img)\n",
    "    \n",
    "vid_writer.release()\n",
    "cap.release()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp ../../data/output/John_Wick_small_matterport01.avi gs://my_bucket_dlcv/data/output/John_Wick_small_matterport01.avi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다른 동영상에 적용. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input_path = '../../data/video/London_Street.mp4'\n",
    "# video output 의 포맷은 avi 로 반드시 설정 필요. \n",
    "video_output_path = '../../data/output/London_Street_matterport01.avi'\n",
    "\n",
    "cap = cv2.VideoCapture(video_input_path)\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "vid_writer = cv2.VideoWriter(video_output_path, codec, fps, (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"총 Frame 개수: {0:}\".format(total))\n",
    "\n",
    "import time\n",
    "\n",
    "frame_index = 0\n",
    "while True:\n",
    "    \n",
    "    hasFrame, image_frame = cap.read()\n",
    "    if not hasFrame:\n",
    "        print('End of frame')\n",
    "        break\n",
    "    \n",
    "    frame_index += 1\n",
    "    print(\"frame index:{0:}\".format(frame_index), end=\" \")\n",
    "    r = get_segment_result([image_frame], verbose=1)[0]\n",
    "    segmented_img = get_segmented_image(image_frame, r['rois'], r['masks'], r['class_ids'], \n",
    "                                    class_names, r['scores'])\n",
    "    vid_writer.write(segmented_img)\n",
    "    \n",
    "vid_writer.release()\n",
    "cap.release()       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp ../../data/output/London_Street_matterport01.avi gs://my_bucket_dlcv/data/output/London_Street_matterport01.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf113] *",
   "language": "python",
   "name": "conda-env-tf113-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

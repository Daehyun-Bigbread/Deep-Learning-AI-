{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tf113] *","language":"python","name":"conda-env-tf113-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"Matterport패키지를_이용한_Segmentation_colab_mask_pixel_position.ipynb","provenance":[{"file_id":"1mm8DN_5u0vo9-8QwYA2BEqN8l2ViomYD","timestamp":1597842239431}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KRN82aS84qir","colab_type":"text"},"source":["### Matterport 패키지를 이용하여 pretrained coco 모델을 로딩 후 단일 이미지와 영상 Segmentation 수행. "]},{"cell_type":"markdown","metadata":{"id":"C9E7diOq4-8_","colab_type":"text"},"source":["\n","### 본 실습 예제는 GPU를 활용하므로 상단 메뉴에서 런타임->런타임 유형 변경에서 GPU를 선택해 주십시요. \n","\n","tensorflow, keras 설치 및 강의 실습코드/데이터 Download\n","\n","**공지**\n","\n","현재(2020년 8월 11일) Colab에서 GPU 커널 적용시 tensorflow 1.13으로 downgrade가 되지 않습니다. \n","때문에 colab에서는 Segmentation 학습 시 tensorflow 1.15, keras 2.3 을 설치하겠습니다. \n","\n","Colab 버전colab에서 pip 명령어를 이용하여 tensorflow 1.15, keras 2.3를 소스코드 커널 기동시 마다 설치해야 합니다\n","\n","Colab의 tensorflow는 2020년 기준으로 2.2 이며, keras는 2.3입니다. 실습코드는 tensorflow 1.13과 1.15, keras 2.2와 2.3 기준으로 되어 있으므로 이를 downgrade해야 합니다.\n","\n","pip를 이용하여 tensorflow 1.15을 설치하면 자동으로 downgrade 됩니다.\n","\n","OpenCV는 Colab에서 이미 설치 되어 있으니 추가설치는 필요 없습니다.\n","\n","강의 실습코드와 데이터는 https://github.com/chulminkw/DLCV.git 에서 다운로드 할 수 있습니다. "]},{"cell_type":"code","metadata":{"id":"jIH_6N6G5AJC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597840259180,"user_tz":-540,"elapsed":100406,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"2d22d6ae-1d5d-4360-8c8b-3f429ed10954"},"source":["# 현재 디렉토리는 /content이며 이 디렉토리를 기준으로 실습코드와 데이터를 다운로드 합니다. \n","!pwd\n","!git clone https://github.com/chulminkw/DLCV.git\n","# DLCV 디렉토리가 Download되고 DLCV 밑에 Detection과 Segmentation 디렉토리가 있는 것을 확인\n","!ls -lia \n","!ls -lia DLCV\n","\n","# tensorflow 1.13을 설치합니다. 자동으로 tensorflow 2.2가 1.13으로 downgrade 됩니다. \n","!pip install tensorflow-gpu==1.15.2\n","# keras 2.2를 설치합니다. pip install keras==2.2.1 시 자동으로 2.3에서 2.2.1로 downgrade 됩니다. \n","!pip install keras==2.3.0\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'DLCV'...\n","remote: Enumerating objects: 32, done.\u001b[K\n","remote: Counting objects: 100% (32/32), done.\u001b[K\n","remote: Compressing objects: 100% (28/28), done.\u001b[K\n","remote: Total 191 (delta 12), reused 0 (delta 0), pack-reused 159\u001b[K\n","Receiving objects: 100% (191/191), 138.03 MiB | 42.32 MiB/s, done.\n","Resolving deltas: 100% (69/69), done.\n","total 20\n","4325401 drwxr-xr-x 1 root root 4096 Aug 19 12:29 .\n","3810757 drwxr-xr-x 1 root root 4096 Aug 19 12:28 ..\n","4325402 drwxr-xr-x 1 root root 4096 Aug 10 21:25 .config\n","3810847 drwxr-xr-x 7 root root 4096 Aug 19 12:29 DLCV\n","4456493 drwxr-xr-x 1 root root 4096 Jul 30 16:30 sample_data\n","total 7904\n","3810847 drwxr-xr-x 7 root root    4096 Aug 19 12:29 .\n","4325401 drwxr-xr-x 1 root root    4096 Aug 19 12:29 ..\n","3810924 drwxr-xr-x 2 root root    4096 Aug 19 12:29 colab_tf115_modify_files\n","3810926 drwxr-xr-x 6 root root    4096 Aug 19 12:29 data\n","3810890 drwxr-xr-x 8 root root    4096 Aug 19 12:29 Detection\n","3810875 -rw-r--r-- 1 root root 5992976 Aug 19 12:29 DLCV_Colab_SrcCode_new.zip\n","3810848 drwxr-xr-x 8 root root    4096 Aug 19 12:29 .git\n","3810960 -rw-r--r-- 1 root root 2063693 Aug 19 12:29 labelimg.pptx\n","3810916 -rw-r--r-- 1 root root     142 Aug 19 12:29 README.md\n","3810917 drwxr-xr-x 3 root root    4096 Aug 19 12:29 Segmentation\n","Collecting tensorflow-gpu==1.15.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n","\u001b[K     |████████████████████████████████| 411.0MB 40kB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.18.5)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 58.6MB/s \n","\u001b[?25hCollecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.34.2)\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 54.8MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.12.4)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.9.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.31.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (49.2.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.2.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.1.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=8acdf95b371764b3f253da1ef73cc71cceb141d466f4148571033f757fa55373\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, gast, keras-applications, tensorflow-estimator, tensorflow-gpu\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2\n","Collecting keras==2.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/18/2e1ef121e5560ac24c7ac9e363aa5fa7006c40563c989e7211aba95b793a/Keras-2.3.0-py2.py3-none-any.whl (377kB)\n","\u001b[K     |████████████████████████████████| 378kB 4.6MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (2.10.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.18.5)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.1.2)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.0.8)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (3.13)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.15.0)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","Successfully installed keras-2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KRW8Sg-p5AMj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":95},"executionInfo":{"status":"ok","timestamp":1597840262208,"user_tz":-540,"elapsed":103419,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"08ed2b6d-983c-4ad2-bbe8-dd9a019bd7d2"},"source":["# tensorflow는 1.15, keras는 2.3 버전 확인\n","# GPU가 세팅되어 있지 않으면 상단 메뉴에서 런타임->런타임 유형 변경에서 GPU를 선택한 후 런타임 다시 시작을 선택하고 처음 부터인 tensorflow, keras 설치 부터 다시 시작. \n","import tensorflow as tf\n","import keras\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","# gpu가 세팅되어 있는지 확인. \n","tf.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["1.15.2\n","2.3.0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"fbAKkFm35NPO","colab_type":"text"},"source":["#### Matterport Mask RCNN 패키지 다운로드및 설치 "]},{"cell_type":"code","metadata":{"id":"NrfUAMqv5MMb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597840272398,"user_tz":-540,"elapsed":113603,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"f312816b-12b4-4fe6-f1fa-6a39be7e3093"},"source":["# Mask_RCNN 다운로드 \n","%cd /content/DLCV/Segmentation/mask_rcnn\n","!git clone https://github.com/matterport/Mask_RCNN.git\n","\n","# 다운로드한 Mask_RCNN 디렉토리로 이동하여 Mask_RCNN 패키지 설치. \n","%cd /content/DLCV/Segmentation/mask_rcnn/Mask_RCNN\n","#!pip install -r requirements.txt\n","!python setup.py install"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/DLCV/Segmentation/mask_rcnn\n","Cloning into 'Mask_RCNN'...\n","remote: Enumerating objects: 956, done.\u001b[K\n","remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n","Receiving objects: 100% (956/956), 116.77 MiB | 32.97 MiB/s, done.\n","Resolving deltas: 100% (564/564), done.\n","/content/DLCV/Segmentation/mask_rcnn/Mask_RCNN\n","WARNING:root:Fail load requirements file, so using default ones.\n","running install\n","running bdist_egg\n","running egg_info\n","creating mask_rcnn.egg-info\n","writing mask_rcnn.egg-info/PKG-INFO\n","writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n","writing top-level names to mask_rcnn.egg-info/top_level.txt\n","writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n","reading manifest template 'MANIFEST.in'\n","writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build\n","creating build/lib\n","creating build/lib/mrcnn\n","copying mrcnn/utils.py -> build/lib/mrcnn\n","copying mrcnn/config.py -> build/lib/mrcnn\n","copying mrcnn/parallel_model.py -> build/lib/mrcnn\n","copying mrcnn/model.py -> build/lib/mrcnn\n","copying mrcnn/__init__.py -> build/lib/mrcnn\n","copying mrcnn/visualize.py -> build/lib/mrcnn\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating dist\n","creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing mask_rcnn-2.1-py3.6.egg\n","Copying mask_rcnn-2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n","Adding mask-rcnn 2.1 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n","Processing dependencies for mask-rcnn==2.1\n","Finished processing dependencies for mask-rcnn==2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yDsVPAGX5MfR","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"xIzhVwgV4qiu","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import random\n","import math\n","import numpy as np\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UOI2Ad4Z4qi4","colab_type":"code","colab":{}},"source":["from mrcnn import utils\n","import mrcnn.model as modellib\n","from mrcnn import visualize"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tm9KhVVa4qjD","colab_type":"text"},"source":["#### Matterport로 pretrained된 coco weight 모델을 다운로드함(최초시)\n","* 코랩 버전은 아래 코드로 pretrained 디렉토리를 재 생성해야함. "]},{"cell_type":"code","metadata":{"id":"FsXajsQw-B4x","colab_type":"code","colab":{}},"source":["!rm -rf /content/DLCV/Segmentation/mask_rcnn/pretrained\n","!mkdir /content/DLCV/Segmentation/mask_rcnn/pretrained"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qh7k9vI64qjF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1597840283632,"user_tz":-540,"elapsed":124812,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"fb424550-c101-40b3-8d82-d44f4649ddd8"},"source":["from mrcnn import utils\n","\n","# 코랩 버전 수정\n","#ROOT_DIR = os.path.abspath('.')\n","ROOT_DIR = '/content/DLCV/Segmentation/mask_rcnn'\n","# 최초에는 coco pretrained 모델을 다운로드함. \n","COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"pretrained/mask_rcnn_coco.h5\")\n","\n","if not os.path.exists(COCO_MODEL_PATH):\n","    utils.download_trained_weights(COCO_MODEL_PATH)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading pretrained model to /content/DLCV/Segmentation/mask_rcnn/pretrained/mask_rcnn_coco.h5 ...\n","... done downloading pretrained model!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EyjW1Dn64qjM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1597840286232,"user_tz":-540,"elapsed":127408,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"6b379c60-4a0b-4e70-bb58-ab9a70baef0a"},"source":["!ls /content/DLCV/Segmentation/mask_rcnn/pretrained"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mask_rcnn_coco.h5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vFslGRay4qjT","colab_type":"text"},"source":["#### MASK RCNN 모델을 위한 Config 설정"]},{"cell_type":"code","metadata":{"id":"3RUTqZ9v4qjV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":996},"executionInfo":{"status":"ok","timestamp":1597840286245,"user_tz":-540,"elapsed":124497,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"5f9c2ed4-bb30-42b0-fd94-3836fa914834"},"source":["from mrcnn.config import Config\n","\n","infer_config = Config()\n","infer_config.BATCH_SIZE=4\n","infer_config.display()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Configurations:\n","BACKBONE                       resnet101\n","BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n","BATCH_SIZE                     4\n","BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n","COMPUTE_BACKBONE_SHAPE         None\n","DETECTION_MAX_INSTANCES        100\n","DETECTION_MIN_CONFIDENCE       0.7\n","DETECTION_NMS_THRESHOLD        0.3\n","FPN_CLASSIF_FC_LAYERS_SIZE     1024\n","GPU_COUNT                      1\n","GRADIENT_CLIP_NORM             5.0\n","IMAGES_PER_GPU                 2\n","IMAGE_CHANNEL_COUNT            3\n","IMAGE_MAX_DIM                  1024\n","IMAGE_META_SIZE                13\n","IMAGE_MIN_DIM                  800\n","IMAGE_MIN_SCALE                0\n","IMAGE_RESIZE_MODE              square\n","IMAGE_SHAPE                    [1024 1024    3]\n","LEARNING_MOMENTUM              0.9\n","LEARNING_RATE                  0.001\n","LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n","MASK_POOL_SIZE                 14\n","MASK_SHAPE                     [28, 28]\n","MAX_GT_INSTANCES               100\n","MEAN_PIXEL                     [123.7 116.8 103.9]\n","MINI_MASK_SHAPE                (56, 56)\n","NAME                           None\n","NUM_CLASSES                    1\n","POOL_SIZE                      7\n","POST_NMS_ROIS_INFERENCE        1000\n","POST_NMS_ROIS_TRAINING         2000\n","PRE_NMS_LIMIT                  6000\n","ROI_POSITIVE_RATIO             0.33\n","RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n","RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n","RPN_ANCHOR_STRIDE              1\n","RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n","RPN_NMS_THRESHOLD              0.7\n","RPN_TRAIN_ANCHORS_PER_IMAGE    256\n","STEPS_PER_EPOCH                1000\n","TOP_DOWN_PYRAMID_SIZE          256\n","TRAIN_BN                       False\n","TRAIN_ROIS_PER_IMAGE           200\n","USE_MINI_MASK                  True\n","USE_RPN_ROIS                   True\n","VALIDATION_STEPS               50\n","WEIGHT_DECAY                   0.0001\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IgA_EMNc4qjc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":996},"executionInfo":{"status":"ok","timestamp":1597840286248,"user_tz":-540,"elapsed":119058,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"db791161-922f-4051-e40e-328ed9cd4313"},"source":["# Config 클래스를 상속받아서 사용\n","from mrcnn.config import Config\n","\n","#환경 변수는 모두 대문자 \n","class InferenceConfig(Config):\n","    # inference시에는 batch size를 1로 설정. 그리고 IMAGES_PER_GPU도 1로 설정. \n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","    # NAME은 반드시 주어야 한다. \n","    NAME='coco_infer'\n","    NUM_CLASSES=81\n","    \n","\n","infer_config = InferenceConfig()\n","infer_config.display()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Configurations:\n","BACKBONE                       resnet101\n","BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n","BATCH_SIZE                     1\n","BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n","COMPUTE_BACKBONE_SHAPE         None\n","DETECTION_MAX_INSTANCES        100\n","DETECTION_MIN_CONFIDENCE       0.7\n","DETECTION_NMS_THRESHOLD        0.3\n","FPN_CLASSIF_FC_LAYERS_SIZE     1024\n","GPU_COUNT                      1\n","GRADIENT_CLIP_NORM             5.0\n","IMAGES_PER_GPU                 1\n","IMAGE_CHANNEL_COUNT            3\n","IMAGE_MAX_DIM                  1024\n","IMAGE_META_SIZE                93\n","IMAGE_MIN_DIM                  800\n","IMAGE_MIN_SCALE                0\n","IMAGE_RESIZE_MODE              square\n","IMAGE_SHAPE                    [1024 1024    3]\n","LEARNING_MOMENTUM              0.9\n","LEARNING_RATE                  0.001\n","LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n","MASK_POOL_SIZE                 14\n","MASK_SHAPE                     [28, 28]\n","MAX_GT_INSTANCES               100\n","MEAN_PIXEL                     [123.7 116.8 103.9]\n","MINI_MASK_SHAPE                (56, 56)\n","NAME                           coco_infer\n","NUM_CLASSES                    81\n","POOL_SIZE                      7\n","POST_NMS_ROIS_INFERENCE        1000\n","POST_NMS_ROIS_TRAINING         2000\n","PRE_NMS_LIMIT                  6000\n","ROI_POSITIVE_RATIO             0.33\n","RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n","RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n","RPN_ANCHOR_STRIDE              1\n","RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n","RPN_NMS_THRESHOLD              0.7\n","RPN_TRAIN_ANCHORS_PER_IMAGE    256\n","STEPS_PER_EPOCH                1000\n","TOP_DOWN_PYRAMID_SIZE          256\n","TRAIN_BN                       False\n","TRAIN_ROIS_PER_IMAGE           200\n","USE_MINI_MASK                  True\n","USE_RPN_ROIS                   True\n","VALIDATION_STEPS               50\n","WEIGHT_DECAY                   0.0001\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZA-PmQik4qjj","colab_type":"text"},"source":["#### COCO ID와 클래스명 매핑"]},{"cell_type":"code","metadata":{"id":"5P7mTtpw4qjl","colab_type":"code","colab":{}},"source":["# matterport는 0을 Background로, 1부터 80까지 coco dataset 클래스 id/클래스 명 매핑. \n","labels_to_names = {0:'BG',1: 'person',2: 'bicycle',3: 'car',4: 'motorbike',5: 'aeroplane',6: 'bus',7: 'train',8: 'truck',9: 'boat',10: 'traffic light',\n","                   11: 'fire hydrant',12: 'stop sign',13: 'parking meter',14: 'bench',15: 'bird',16: 'cat',17: 'dog',18: 'horse',19: 'sheep',20: 'cow',\n","                   21: 'elephant',22: 'bear',23: 'zebra',24: 'giraffe',25: 'backpack',26: 'umbrella',27: 'handbag',28: 'tie',29: 'suitcase',30: 'frisbee',\n","                   31: 'skis',32: 'snowboard',33: 'sports ball',34: 'kite',35: 'baseball bat',36: 'baseball glove',37: 'skateboard',38: 'surfboard',39: 'tennis racket',40: 'bottle',\n","                   41: 'wine glass',42: 'cup',43: 'fork',44: 'knife',45: 'spoon',46: 'bowl',47: 'banana',48: 'apple',49: 'sandwich',50: 'orange',\n","                   51: 'broccoli',52: 'carrot',53: 'hot dog',54: 'pizza',55: 'donut',56: 'cake',57: 'chair',58: 'sofa',59: 'pottedplant',60: 'bed',\n","                   61: 'diningtable',62: 'toilet',63: 'tvmonitor',64: 'laptop',65: 'mouse',66: 'remote', 67: 'keyboard',68: 'cell phone',69: 'microwave',70: 'oven',\n","                   71: 'toaster',72: 'sink',73: 'refrigerator',74: 'book',75: 'clock',76: 'vase',77: 'scissors',78: 'teddy bear',79: 'hair drier',80: 'toothbrush' }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qmPZU40s4qjq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":433},"executionInfo":{"status":"ok","timestamp":1597840295172,"user_tz":-540,"elapsed":123543,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"1ff18e82-9978-4e63-ce04-5dc61ff2d450"},"source":["# MS-COCO 기반으로 Pretrained 된 모델을 로딩\n","import mrcnn.model as modellib\n","\n","MODEL_DIR = os.path.join(ROOT_DIR,'snapshots') \n","print(MODEL_DIR)\n","model = modellib.MaskRCNN(mode=\"inference\",  model_dir=MODEL_DIR, config=infer_config)\n","\n","model.load_weights(COCO_MODEL_PATH, by_name=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/DLCV/Segmentation/mask_rcnn/snapshots\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /content/DLCV/Segmentation/mask_rcnn/Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/DLCV/Segmentation/mask_rcnn/Mask_RCNN/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/DLCV/Segmentation/mask_rcnn/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /content/DLCV/Segmentation/mask_rcnn/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n","\n","WARNING:tensorflow:From /content/DLCV/Segmentation/mask_rcnn/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n","\n","WARNING:tensorflow:From /content/DLCV/Segmentation/mask_rcnn/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I1-cASRB4qjv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":169},"executionInfo":{"status":"ok","timestamp":1597840306752,"user_tz":-540,"elapsed":132926,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"2d73a862-a60c-43b4-e556-541624a6848f"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline \n","\n","default_dir = '/content/DLCV'\n","beatles_img = cv2.imread(os.path.join(default_dir, 'data/image/beatles01.jpg'))\n","# matterport는 내부적으로 image처리를 위해 skimage를 이용하므로 BGR2RGB처리함. \n","beatles_img_rgb = cv2.cvtColor(beatles_img, cv2.COLOR_BGR2RGB)\n"," \n","results = model.detect([beatles_img_rgb], verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Processing 1 images\n","image                    shape: (633, 806, 3)         min:    0.00000  max:  255.00000  uint8\n","molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n","image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n","anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lpV6liaG4qj1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597840426250,"user_tz":-540,"elapsed":764,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"05a471be-0b10-4daf-f233-015dfcc54b65"},"source":["len(results), results[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1,\n"," {'class_ids': array([1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32),\n","  'masks': array([[[False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          ...,\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False]],\n","  \n","         [[False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          ...,\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False]],\n","  \n","         [[False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          ...,\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False]],\n","  \n","         ...,\n","  \n","         [[False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          ...,\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False]],\n","  \n","         [[False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          ...,\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False]],\n","  \n","         [[False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          ...,\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False]]]),\n","  'rois': array([[260, 552, 572, 729],\n","         [265, 228, 551, 375],\n","         [257,  47, 561, 206],\n","         [276, 395, 555, 552],\n","         [226, 607, 294, 627],\n","         [236, 473, 260, 502],\n","         [224, 436, 241, 455],\n","         [227, 453, 247, 472],\n","         [247, 139, 345, 257],\n","         [237, 489, 283, 516],\n","         [224, 381, 239, 399],\n","         [217, 364, 229, 378],\n","         [228, 508, 296, 583],\n","         [233, 313, 266, 348],\n","         [218, 399, 228, 413],\n","         [221, 424, 233, 437],\n","         [218, 412, 228, 424],\n","         [231, 466, 254, 479]], dtype=int32),\n","  'scores': array([0.9998393 , 0.9998117 , 0.99958915, 0.9994247 , 0.9921354 ,\n","         0.9794605 , 0.97927654, 0.96658874, 0.96063304, 0.9545476 ,\n","         0.9360076 , 0.9248212 , 0.918216  , 0.91627973, 0.83873004,\n","         0.8154047 , 0.80258876, 0.72912586], dtype=float32)})"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"o6E9wejXtmHT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1597841212102,"user_tz":-540,"elapsed":849,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"cea975a4-e13f-4a7f-cf00-c045c5b30efc"},"source":["\n","# mask array 추출\n","mask_array  = results[0]['masks']\n","# class id 추출 \n","class_array = results[0]['class_ids']\n","print(class_array)\n","print(mask_array.shape, class_array.shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3]\n","(633, 806, 18) (18,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hBDWkp_kwI-P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"ok","timestamp":1597841743877,"user_tz":-540,"elapsed":841,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"3bd33178-c492-4f05-ea1d-8ac34a18cf6f"},"source":["# mask_array값 중에서 True 즉 값이 0 보다 큰 값에 대한 array의 위치 인덱스를 추출하고 이를 다시 transpose로 변환. \n","mask_array_index = np.transpose((mask_array > 0).nonzero())\n","print(mask_array_index)\n","print(mask_array_index.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[217 366  11]\n"," [217 367  11]\n"," [217 368  11]\n"," ...\n"," [563 703   0]\n"," [563 704   0]\n"," [563 705   0]]\n","(83388, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2UME33mHwK1s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597842204671,"user_tz":-540,"elapsed":847,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"3790c2e6-a029-47ac-a5f6-0059b20b1260"},"source":["# 추출된 전체 mask 위치 인덱스와 class_id를 기반으로 순차적으로 class_id별 mask 위치 인덱스를 추출하여 total_class_id_positio에 Set형태로 저장. \n","total_class_id_position_list = []\n","for class_array_index, class_id in enumerate(class_array):\n","  #print('class_array_index:', class_array_index, ' class_id:', class_id)\n","  #print('mask position index:', mask_array_index[mask_array_index[:,2] == class_array_index])\n","  class_id_position_set = (class_id, mask_array_index[:, :2])\n","  total_class_id_position_list.append(class_id_position_set)\n","\n","print(total_class_id_position_list)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["class_array_index: 0  class_id: 1\n","mask position index: [[268 665   0]\n"," [268 666   0]\n"," [268 667   0]\n"," ...\n"," [563 703   0]\n"," [563 704   0]\n"," [563 705   0]]\n","class_array_index: 1  class_id: 1\n","mask position index: [[266 304   1]\n"," [266 305   1]\n"," [266 306   1]\n"," ...\n"," [546 364   1]\n"," [546 365   1]\n"," [546 366   1]]\n","class_array_index: 2  class_id: 1\n","mask position index: [[263 128   2]\n"," [263 129   2]\n"," [263 130   2]\n"," ...\n"," [558  66   2]\n"," [558  67   2]\n"," [558  68   2]]\n","class_array_index: 3  class_id: 1\n","mask position index: [[277 479   3]\n"," [277 480   3]\n"," [277 481   3]\n"," ...\n"," [547 532   3]\n"," [547 533   3]\n"," [547 534   3]]\n","class_array_index: 4  class_id: 1\n","mask position index: [[228 614   4]\n"," [228 615   4]\n"," [228 616   4]\n"," ...\n"," [291 619   4]\n"," [291 620   4]\n"," [292 619   4]]\n","class_array_index: 5  class_id: 3\n","mask position index: [[236 477   5]\n"," [236 478   5]\n"," [236 479   5]\n"," ...\n"," [257 485   5]\n"," [257 486   5]\n"," [257 487   5]]\n","class_array_index: 6  class_id: 3\n","mask position index: [[224 440   6]\n"," [224 441   6]\n"," [224 442   6]\n"," [224 443   6]\n"," [224 444   6]\n"," [224 445   6]\n"," [224 446   6]\n"," [224 447   6]\n"," [224 448   6]\n"," [224 449   6]\n"," [224 450   6]\n"," [224 451   6]\n"," [225 439   6]\n"," [225 440   6]\n"," [225 441   6]\n"," [225 442   6]\n"," [225 443   6]\n"," [225 444   6]\n"," [225 445   6]\n"," [225 446   6]\n"," [225 447   6]\n"," [225 448   6]\n"," [225 449   6]\n"," [225 450   6]\n"," [225 451   6]\n"," [225 452   6]\n"," [226 438   6]\n"," [226 439   6]\n"," [226 440   6]\n"," [226 441   6]\n"," [226 442   6]\n"," [226 443   6]\n"," [226 444   6]\n"," [226 445   6]\n"," [226 446   6]\n"," [226 447   6]\n"," [226 448   6]\n"," [226 449   6]\n"," [226 450   6]\n"," [226 451   6]\n"," [226 452   6]\n"," [226 453   6]\n"," [227 438   6]\n"," [227 439   6]\n"," [227 440   6]\n"," [227 441   6]\n"," [227 442   6]\n"," [227 443   6]\n"," [227 444   6]\n"," [227 445   6]\n"," [227 446   6]\n"," [227 447   6]\n"," [227 448   6]\n"," [227 449   6]\n"," [227 450   6]\n"," [227 451   6]\n"," [227 452   6]\n"," [227 453   6]\n"," [228 438   6]\n"," [228 439   6]\n"," [228 440   6]\n"," [228 441   6]\n"," [228 442   6]\n"," [228 443   6]\n"," [228 444   6]\n"," [228 445   6]\n"," [228 446   6]\n"," [228 447   6]\n"," [228 448   6]\n"," [228 449   6]\n"," [228 450   6]\n"," [228 451   6]\n"," [228 452   6]\n"," [228 453   6]\n"," [229 437   6]\n"," [229 438   6]\n"," [229 439   6]\n"," [229 440   6]\n"," [229 441   6]\n"," [229 442   6]\n"," [229 443   6]\n"," [229 444   6]\n"," [229 445   6]\n"," [229 446   6]\n"," [229 447   6]\n"," [229 448   6]\n"," [229 449   6]\n"," [229 450   6]\n"," [229 451   6]\n"," [229 452   6]\n"," [229 453   6]\n"," [230 437   6]\n"," [230 438   6]\n"," [230 439   6]\n"," [230 440   6]\n"," [230 441   6]\n"," [230 442   6]\n"," [230 443   6]\n"," [230 444   6]\n"," [230 445   6]\n"," [230 446   6]\n"," [230 447   6]\n"," [230 448   6]\n"," [230 449   6]\n"," [230 450   6]\n"," [230 451   6]\n"," [230 452   6]\n"," [230 453   6]\n"," [230 454   6]\n"," [231 437   6]\n"," [231 438   6]\n"," [231 439   6]\n"," [231 440   6]\n"," [231 441   6]\n"," [231 442   6]\n"," [231 443   6]\n"," [231 444   6]\n"," [231 445   6]\n"," [231 446   6]\n"," [231 447   6]\n"," [231 448   6]\n"," [231 449   6]\n"," [231 450   6]\n"," [231 451   6]\n"," [231 452   6]\n"," [231 453   6]\n"," [231 454   6]\n"," [232 436   6]\n"," [232 437   6]\n"," [232 438   6]\n"," [232 439   6]\n"," [232 440   6]\n"," [232 441   6]\n"," [232 442   6]\n"," [232 443   6]\n"," [232 444   6]\n"," [232 445   6]\n"," [232 446   6]\n"," [232 447   6]\n"," [232 448   6]\n"," [232 449   6]\n"," [232 450   6]\n"," [232 451   6]\n"," [232 452   6]\n"," [232 453   6]\n"," [232 454   6]\n"," [233 436   6]\n"," [233 437   6]\n"," [233 438   6]\n"," [233 439   6]\n"," [233 440   6]\n"," [233 441   6]\n"," [233 442   6]\n"," [233 443   6]\n"," [233 444   6]\n"," [233 445   6]\n"," [233 446   6]\n"," [233 447   6]\n"," [233 448   6]\n"," [233 449   6]\n"," [233 450   6]\n"," [233 451   6]\n"," [233 452   6]\n"," [233 453   6]\n"," [234 437   6]\n"," [234 438   6]\n"," [234 439   6]\n"," [234 440   6]\n"," [234 441   6]\n"," [234 442   6]\n"," [234 443   6]\n"," [234 444   6]\n"," [234 445   6]\n"," [234 446   6]\n"," [234 447   6]\n"," [234 448   6]\n"," [234 449   6]\n"," [234 450   6]\n"," [234 451   6]\n"," [234 452   6]\n"," [234 453   6]\n"," [235 437   6]\n"," [235 438   6]\n"," [235 439   6]\n"," [235 440   6]\n"," [235 441   6]\n"," [235 442   6]\n"," [235 443   6]\n"," [235 444   6]\n"," [235 445   6]\n"," [235 446   6]\n"," [235 447   6]\n"," [235 448   6]\n"," [235 449   6]\n"," [235 450   6]\n"," [235 451   6]\n"," [235 452   6]\n"," [235 453   6]\n"," [236 437   6]\n"," [236 438   6]\n"," [236 439   6]\n"," [236 440   6]\n"," [236 441   6]\n"," [236 442   6]\n"," [236 443   6]\n"," [236 444   6]\n"," [236 445   6]\n"," [236 446   6]\n"," [236 447   6]\n"," [236 448   6]\n"," [236 449   6]\n"," [236 450   6]\n"," [236 451   6]\n"," [236 452   6]\n"," [236 453   6]\n"," [237 438   6]\n"," [237 439   6]\n"," [237 440   6]\n"," [237 441   6]\n"," [237 442   6]\n"," [237 443   6]\n"," [237 444   6]\n"," [237 445   6]\n"," [237 446   6]\n"," [237 447   6]\n"," [237 448   6]\n"," [237 449   6]\n"," [237 450   6]\n"," [237 451   6]\n"," [237 452   6]\n"," [237 453   6]\n"," [238 438   6]\n"," [238 439   6]\n"," [238 440   6]\n"," [238 441   6]\n"," [238 442   6]\n"," [238 443   6]\n"," [238 444   6]\n"," [238 445   6]\n"," [238 446   6]\n"," [238 447   6]\n"," [238 448   6]\n"," [238 449   6]\n"," [238 450   6]\n"," [238 451   6]\n"," [238 452   6]\n"," [239 440   6]\n"," [239 441   6]\n"," [239 442   6]\n"," [239 443   6]\n"," [239 444   6]\n"," [239 445   6]\n"," [239 446   6]\n"," [239 447   6]\n"," [239 448   6]\n"," [239 449   6]\n"," [239 450   6]\n"," [239 451   6]]\n","class_array_index: 7  class_id: 3\n","mask position index: [[227 459   7]\n"," [227 460   7]\n"," [227 461   7]\n"," [227 462   7]\n"," [228 456   7]\n"," [228 457   7]\n"," [228 458   7]\n"," [228 459   7]\n"," [228 460   7]\n"," [228 461   7]\n"," [228 462   7]\n"," [228 463   7]\n"," [228 464   7]\n"," [228 465   7]\n"," [228 466   7]\n"," [228 467   7]\n"," [228 468   7]\n"," [228 469   7]\n"," [229 456   7]\n"," [229 457   7]\n"," [229 458   7]\n"," [229 459   7]\n"," [229 460   7]\n"," [229 461   7]\n"," [229 462   7]\n"," [229 463   7]\n"," [229 464   7]\n"," [229 465   7]\n"," [229 466   7]\n"," [229 467   7]\n"," [229 468   7]\n"," [229 469   7]\n"," [229 470   7]\n"," [229 471   7]\n"," [230 455   7]\n"," [230 456   7]\n"," [230 457   7]\n"," [230 458   7]\n"," [230 459   7]\n"," [230 460   7]\n"," [230 461   7]\n"," [230 462   7]\n"," [230 463   7]\n"," [230 464   7]\n"," [230 465   7]\n"," [230 466   7]\n"," [230 467   7]\n"," [230 468   7]\n"," [230 469   7]\n"," [230 470   7]\n"," [230 471   7]\n"," [231 455   7]\n"," [231 456   7]\n"," [231 457   7]\n"," [231 458   7]\n"," [231 459   7]\n"," [231 460   7]\n"," [231 461   7]\n"," [231 462   7]\n"," [231 463   7]\n"," [231 464   7]\n"," [231 465   7]\n"," [231 466   7]\n"," [231 467   7]\n"," [231 468   7]\n"," [231 469   7]\n"," [231 470   7]\n"," [231 471   7]\n"," [232 455   7]\n"," [232 456   7]\n"," [232 457   7]\n"," [232 458   7]\n"," [232 459   7]\n"," [232 460   7]\n"," [232 461   7]\n"," [232 462   7]\n"," [232 463   7]\n"," [232 464   7]\n"," [232 465   7]\n"," [232 466   7]\n"," [232 467   7]\n"," [232 468   7]\n"," [232 469   7]\n"," [232 470   7]\n"," [232 471   7]\n"," [233 454   7]\n"," [233 455   7]\n"," [233 456   7]\n"," [233 457   7]\n"," [233 458   7]\n"," [233 459   7]\n"," [233 460   7]\n"," [233 461   7]\n"," [233 462   7]\n"," [233 463   7]\n"," [233 464   7]\n"," [233 465   7]\n"," [233 466   7]\n"," [233 467   7]\n"," [233 468   7]\n"," [233 469   7]\n"," [233 470   7]\n"," [233 471   7]\n"," [234 454   7]\n"," [234 455   7]\n"," [234 456   7]\n"," [234 457   7]\n"," [234 458   7]\n"," [234 459   7]\n"," [234 460   7]\n"," [234 461   7]\n"," [234 462   7]\n"," [234 463   7]\n"," [234 464   7]\n"," [234 465   7]\n"," [234 466   7]\n"," [234 467   7]\n"," [234 468   7]\n"," [234 469   7]\n"," [234 470   7]\n"," [234 471   7]\n"," [235 454   7]\n"," [235 455   7]\n"," [235 456   7]\n"," [235 457   7]\n"," [235 458   7]\n"," [235 459   7]\n"," [235 460   7]\n"," [235 461   7]\n"," [235 462   7]\n"," [235 463   7]\n"," [235 464   7]\n"," [235 465   7]\n"," [235 466   7]\n"," [235 467   7]\n"," [235 468   7]\n"," [235 469   7]\n"," [235 470   7]\n"," [236 454   7]\n"," [236 455   7]\n"," [236 456   7]\n"," [236 457   7]\n"," [236 458   7]\n"," [236 459   7]\n"," [236 460   7]\n"," [236 461   7]\n"," [236 462   7]\n"," [236 463   7]\n"," [236 464   7]\n"," [236 465   7]\n"," [236 466   7]\n"," [236 467   7]\n"," [236 468   7]\n"," [236 469   7]\n"," [236 470   7]\n"," [237 454   7]\n"," [237 455   7]\n"," [237 456   7]\n"," [237 457   7]\n"," [237 458   7]\n"," [237 459   7]\n"," [237 460   7]\n"," [237 461   7]\n"," [237 462   7]\n"," [237 463   7]\n"," [237 464   7]\n"," [237 465   7]\n"," [237 466   7]\n"," [237 467   7]\n"," [237 468   7]\n"," [237 469   7]\n"," [237 470   7]\n"," [238 454   7]\n"," [238 455   7]\n"," [238 456   7]\n"," [238 457   7]\n"," [238 458   7]\n"," [238 459   7]\n"," [238 460   7]\n"," [238 461   7]\n"," [238 462   7]\n"," [238 463   7]\n"," [238 464   7]\n"," [238 465   7]\n"," [238 466   7]\n"," [238 467   7]\n"," [238 468   7]\n"," [238 469   7]\n"," [239 454   7]\n"," [239 455   7]\n"," [239 456   7]\n"," [239 457   7]\n"," [239 458   7]\n"," [239 459   7]\n"," [239 460   7]\n"," [239 461   7]\n"," [239 462   7]\n"," [239 463   7]\n"," [239 464   7]\n"," [239 465   7]\n"," [239 466   7]\n"," [239 467   7]\n"," [239 468   7]\n"," [239 469   7]\n"," [240 453   7]\n"," [240 454   7]\n"," [240 455   7]\n"," [240 456   7]\n"," [240 457   7]\n"," [240 458   7]\n"," [240 459   7]\n"," [240 460   7]\n"," [240 461   7]\n"," [240 462   7]\n"," [240 463   7]\n"," [240 464   7]\n"," [240 465   7]\n"," [240 466   7]\n"," [240 467   7]\n"," [240 468   7]\n"," [241 453   7]\n"," [241 454   7]\n"," [241 455   7]\n"," [241 456   7]\n"," [241 457   7]\n"," [241 458   7]\n"," [241 459   7]\n"," [241 460   7]\n"," [241 461   7]\n"," [241 462   7]\n"," [241 463   7]\n"," [241 464   7]\n"," [241 465   7]\n"," [241 466   7]\n"," [241 467   7]\n"," [242 453   7]\n"," [242 454   7]\n"," [242 455   7]\n"," [242 456   7]\n"," [242 457   7]\n"," [242 458   7]\n"," [242 459   7]\n"," [242 460   7]\n"," [242 461   7]\n"," [242 462   7]\n"," [242 463   7]\n"," [242 464   7]\n"," [242 465   7]\n"," [242 466   7]\n"," [243 453   7]\n"," [243 454   7]\n"," [243 455   7]\n"," [243 456   7]\n"," [243 457   7]\n"," [243 458   7]\n"," [243 459   7]\n"," [243 460   7]\n"," [243 461   7]\n"," [243 462   7]\n"," [243 463   7]\n"," [243 464   7]\n"," [243 465   7]\n"," [243 466   7]\n"," [244 454   7]\n"," [244 455   7]\n"," [244 456   7]\n"," [244 457   7]\n"," [244 458   7]\n"," [244 459   7]\n"," [244 460   7]\n"," [244 461   7]\n"," [244 462   7]\n"," [244 463   7]\n"," [244 464   7]\n"," [244 465   7]\n"," [245 455   7]]\n","class_array_index: 8  class_id: 3\n","mask position index: [[248 185   8]\n"," [248 186   8]\n"," [248 187   8]\n"," ...\n"," [340 216   8]\n"," [340 217   8]\n"," [340 218   8]]\n","class_array_index: 9  class_id: 3\n","mask position index: [[241 503   9]\n"," [241 504   9]\n"," [241 505   9]\n"," ...\n"," [280 512   9]\n"," [281 511   9]\n"," [281 512   9]]\n","class_array_index: 10  class_id: 3\n","mask position index: [[224 385  10]\n"," [224 386  10]\n"," [224 387  10]\n"," [224 388  10]\n"," [224 389  10]\n"," [224 390  10]\n"," [224 391  10]\n"," [224 392  10]\n"," [224 393  10]\n"," [225 384  10]\n"," [225 385  10]\n"," [225 386  10]\n"," [225 387  10]\n"," [225 388  10]\n"," [225 389  10]\n"," [225 390  10]\n"," [225 391  10]\n"," [225 392  10]\n"," [225 393  10]\n"," [225 394  10]\n"," [225 395  10]\n"," [226 384  10]\n"," [226 385  10]\n"," [226 386  10]\n"," [226 387  10]\n"," [226 388  10]\n"," [226 389  10]\n"," [226 390  10]\n"," [226 391  10]\n"," [226 392  10]\n"," [226 393  10]\n"," [226 394  10]\n"," [226 395  10]\n"," [227 383  10]\n"," [227 384  10]\n"," [227 385  10]\n"," [227 386  10]\n"," [227 387  10]\n"," [227 388  10]\n"," [227 389  10]\n"," [227 390  10]\n"," [227 391  10]\n"," [227 392  10]\n"," [227 393  10]\n"," [227 394  10]\n"," [227 395  10]\n"," [227 396  10]\n"," [228 382  10]\n"," [228 383  10]\n"," [228 384  10]\n"," [228 385  10]\n"," [228 386  10]\n"," [228 387  10]\n"," [228 388  10]\n"," [228 389  10]\n"," [228 390  10]\n"," [228 391  10]\n"," [228 392  10]\n"," [228 393  10]\n"," [228 394  10]\n"," [228 395  10]\n"," [228 396  10]\n"," [228 397  10]\n"," [229 382  10]\n"," [229 383  10]\n"," [229 384  10]\n"," [229 385  10]\n"," [229 386  10]\n"," [229 387  10]\n"," [229 388  10]\n"," [229 389  10]\n"," [229 390  10]\n"," [229 391  10]\n"," [229 392  10]\n"," [229 393  10]\n"," [229 394  10]\n"," [229 395  10]\n"," [229 396  10]\n"," [229 397  10]\n"," [230 382  10]\n"," [230 383  10]\n"," [230 384  10]\n"," [230 385  10]\n"," [230 386  10]\n"," [230 387  10]\n"," [230 388  10]\n"," [230 389  10]\n"," [230 390  10]\n"," [230 391  10]\n"," [230 392  10]\n"," [230 393  10]\n"," [230 394  10]\n"," [230 395  10]\n"," [230 396  10]\n"," [230 397  10]\n"," [231 382  10]\n"," [231 383  10]\n"," [231 384  10]\n"," [231 385  10]\n"," [231 386  10]\n"," [231 387  10]\n"," [231 388  10]\n"," [231 389  10]\n"," [231 390  10]\n"," [231 391  10]\n"," [231 392  10]\n"," [231 393  10]\n"," [231 394  10]\n"," [231 395  10]\n"," [231 396  10]\n"," [231 397  10]\n"," [232 382  10]\n"," [232 383  10]\n"," [232 384  10]\n"," [232 385  10]\n"," [232 386  10]\n"," [232 387  10]\n"," [232 388  10]\n"," [232 389  10]\n"," [232 390  10]\n"," [232 391  10]\n"," [232 392  10]\n"," [232 393  10]\n"," [232 394  10]\n"," [232 395  10]\n"," [232 396  10]\n"," [232 397  10]\n"," [233 382  10]\n"," [233 383  10]\n"," [233 384  10]\n"," [233 385  10]\n"," [233 386  10]\n"," [233 387  10]\n"," [233 388  10]\n"," [233 389  10]\n"," [233 390  10]\n"," [233 391  10]\n"," [233 392  10]\n"," [233 393  10]\n"," [233 394  10]\n"," [233 395  10]\n"," [233 396  10]\n"," [233 397  10]\n"," [234 382  10]\n"," [234 383  10]\n"," [234 384  10]\n"," [234 385  10]\n"," [234 386  10]\n"," [234 387  10]\n"," [234 388  10]\n"," [234 389  10]\n"," [234 390  10]\n"," [234 391  10]\n"," [234 392  10]\n"," [234 393  10]\n"," [234 394  10]\n"," [234 395  10]\n"," [234 396  10]\n"," [234 397  10]\n"," [235 382  10]\n"," [235 383  10]\n"," [235 384  10]\n"," [235 385  10]\n"," [235 386  10]\n"," [235 387  10]\n"," [235 388  10]\n"," [235 389  10]\n"," [235 390  10]\n"," [235 391  10]\n"," [235 392  10]\n"," [235 393  10]\n"," [235 394  10]\n"," [235 395  10]\n"," [235 396  10]\n"," [235 397  10]\n"," [236 382  10]\n"," [236 383  10]\n"," [236 384  10]\n"," [236 385  10]\n"," [236 386  10]\n"," [236 387  10]\n"," [236 388  10]\n"," [236 389  10]\n"," [236 390  10]\n"," [236 391  10]\n"," [236 392  10]\n"," [236 393  10]\n"," [236 394  10]\n"," [236 395  10]\n"," [236 396  10]\n"," [236 397  10]\n"," [237 382  10]\n"," [237 383  10]\n"," [237 384  10]\n"," [237 385  10]\n"," [237 386  10]\n"," [237 387  10]\n"," [237 388  10]\n"," [237 389  10]\n"," [237 390  10]\n"," [237 391  10]\n"," [237 392  10]\n"," [237 393  10]\n"," [237 394  10]\n"," [237 395  10]\n"," [237 396  10]\n"," [237 397  10]\n"," [238 383  10]\n"," [238 384  10]\n"," [238 385  10]\n"," [238 386  10]]\n","class_array_index: 11  class_id: 3\n","mask position index: [[217 366  11]\n"," [217 367  11]\n"," [217 368  11]\n"," [217 369  11]\n"," [217 370  11]\n"," [217 371  11]\n"," [217 372  11]\n"," [217 373  11]\n"," [217 374  11]\n"," [218 365  11]\n"," [218 366  11]\n"," [218 367  11]\n"," [218 368  11]\n"," [218 369  11]\n"," [218 370  11]\n"," [218 371  11]\n"," [218 372  11]\n"," [218 373  11]\n"," [218 374  11]\n"," [218 375  11]\n"," [218 376  11]\n"," [219 365  11]\n"," [219 366  11]\n"," [219 367  11]\n"," [219 368  11]\n"," [219 369  11]\n"," [219 370  11]\n"," [219 371  11]\n"," [219 372  11]\n"," [219 373  11]\n"," [219 374  11]\n"," [219 375  11]\n"," [219 376  11]\n"," [219 377  11]\n"," [220 365  11]\n"," [220 366  11]\n"," [220 367  11]\n"," [220 368  11]\n"," [220 369  11]\n"," [220 370  11]\n"," [220 371  11]\n"," [220 372  11]\n"," [220 373  11]\n"," [220 374  11]\n"," [220 375  11]\n"," [220 376  11]\n"," [220 377  11]\n"," [221 365  11]\n"," [221 366  11]\n"," [221 367  11]\n"," [221 368  11]\n"," [221 369  11]\n"," [221 370  11]\n"," [221 371  11]\n"," [221 372  11]\n"," [221 373  11]\n"," [221 374  11]\n"," [221 375  11]\n"," [221 376  11]\n"," [221 377  11]\n"," [222 364  11]\n"," [222 365  11]\n"," [222 366  11]\n"," [222 367  11]\n"," [222 368  11]\n"," [222 369  11]\n"," [222 370  11]\n"," [222 371  11]\n"," [222 372  11]\n"," [222 373  11]\n"," [222 374  11]\n"," [222 375  11]\n"," [222 376  11]\n"," [222 377  11]\n"," [223 364  11]\n"," [223 365  11]\n"," [223 366  11]\n"," [223 367  11]\n"," [223 368  11]\n"," [223 369  11]\n"," [223 370  11]\n"," [223 371  11]\n"," [223 372  11]\n"," [223 373  11]\n"," [223 374  11]\n"," [223 375  11]\n"," [223 376  11]\n"," [223 377  11]\n"," [224 364  11]\n"," [224 365  11]\n"," [224 366  11]\n"," [224 367  11]\n"," [224 368  11]\n"," [224 369  11]\n"," [224 370  11]\n"," [224 371  11]\n"," [224 372  11]\n"," [224 373  11]\n"," [224 374  11]\n"," [224 375  11]\n"," [224 376  11]\n"," [224 377  11]\n"," [225 364  11]\n"," [225 365  11]\n"," [225 366  11]\n"," [225 367  11]\n"," [225 368  11]\n"," [225 369  11]\n"," [225 370  11]\n"," [225 371  11]\n"," [225 372  11]\n"," [225 373  11]\n"," [225 374  11]\n"," [225 375  11]\n"," [225 376  11]\n"," [225 377  11]\n"," [226 365  11]\n"," [226 366  11]\n"," [226 367  11]\n"," [226 368  11]\n"," [226 369  11]\n"," [226 370  11]\n"," [226 371  11]\n"," [226 372  11]\n"," [226 373  11]\n"," [226 374  11]\n"," [226 375  11]\n"," [226 376  11]\n"," [227 366  11]\n"," [227 367  11]\n"," [227 368  11]\n"," [227 369  11]\n"," [227 370  11]\n"," [227 371  11]\n"," [227 372  11]\n"," [227 373  11]\n"," [227 374  11]\n"," [227 375  11]\n"," [227 376  11]]\n","class_array_index: 12  class_id: 3\n","mask position index: [[229 551  12]\n"," [230 522  12]\n"," [230 523  12]\n"," ...\n"," [293 564  12]\n"," [293 565  12]\n"," [293 566  12]]\n","class_array_index: 13  class_id: 3\n","mask position index: [[234 325  13]\n"," [234 326  13]\n"," [234 327  13]\n"," ...\n"," [264 344  13]\n"," [264 345  13]\n"," [264 346  13]]\n","class_array_index: 14  class_id: 3\n","mask position index: [[218 406  14]\n"," [218 407  14]\n"," [219 401  14]\n"," [219 402  14]\n"," [219 403  14]\n"," [219 404  14]\n"," [219 405  14]\n"," [219 406  14]\n"," [219 407  14]\n"," [219 408  14]\n"," [219 409  14]\n"," [219 410  14]\n"," [220 400  14]\n"," [220 401  14]\n"," [220 402  14]\n"," [220 403  14]\n"," [220 404  14]\n"," [220 405  14]\n"," [220 406  14]\n"," [220 407  14]\n"," [220 408  14]\n"," [220 409  14]\n"," [220 410  14]\n"," [220 411  14]\n"," [221 400  14]\n"," [221 401  14]\n"," [221 402  14]\n"," [221 403  14]\n"," [221 404  14]\n"," [221 405  14]\n"," [221 406  14]\n"," [221 407  14]\n"," [221 408  14]\n"," [221 409  14]\n"," [221 410  14]\n"," [221 411  14]\n"," [222 400  14]\n"," [222 401  14]\n"," [222 402  14]\n"," [222 403  14]\n"," [222 404  14]\n"," [222 405  14]\n"," [222 406  14]\n"," [222 407  14]\n"," [222 408  14]\n"," [222 409  14]\n"," [222 410  14]\n"," [222 411  14]\n"," [223 400  14]\n"," [223 401  14]\n"," [223 402  14]\n"," [223 403  14]\n"," [223 404  14]\n"," [223 405  14]\n"," [223 406  14]\n"," [223 407  14]\n"," [223 408  14]\n"," [223 409  14]\n"," [223 410  14]\n"," [223 411  14]\n"," [224 400  14]\n"," [224 401  14]\n"," [224 402  14]\n"," [224 403  14]\n"," [224 404  14]\n"," [224 405  14]\n"," [224 406  14]\n"," [224 407  14]\n"," [224 408  14]\n"," [224 409  14]\n"," [224 410  14]\n"," [224 411  14]\n"," [225 400  14]\n"," [225 401  14]\n"," [225 402  14]\n"," [225 403  14]\n"," [225 404  14]\n"," [225 405  14]\n"," [225 406  14]\n"," [225 407  14]\n"," [225 408  14]\n"," [225 409  14]\n"," [225 410  14]\n"," [225 411  14]\n"," [226 401  14]\n"," [226 402  14]\n"," [226 403  14]\n"," [226 404  14]\n"," [226 405  14]\n"," [226 406  14]\n"," [226 407  14]\n"," [226 408  14]\n"," [226 409  14]\n"," [226 410  14]\n"," [226 411  14]\n"," [227 404  14]\n"," [227 405  14]\n"," [227 406  14]\n"," [227 407  14]\n"," [227 408  14]]\n","class_array_index: 15  class_id: 3\n","mask position index: [[222 428  15]\n"," [222 429  15]\n"," [222 430  15]\n"," [222 431  15]\n"," [222 432  15]\n"," [223 427  15]\n"," [223 428  15]\n"," [223 429  15]\n"," [223 430  15]\n"," [223 431  15]\n"," [223 432  15]\n"," [223 433  15]\n"," [224 425  15]\n"," [224 426  15]\n"," [224 427  15]\n"," [224 428  15]\n"," [224 429  15]\n"," [224 430  15]\n"," [224 431  15]\n"," [224 432  15]\n"," [224 433  15]\n"," [224 434  15]\n"," [225 425  15]\n"," [225 426  15]\n"," [225 427  15]\n"," [225 428  15]\n"," [225 429  15]\n"," [225 430  15]\n"," [225 431  15]\n"," [225 432  15]\n"," [225 433  15]\n"," [225 434  15]\n"," [225 435  15]\n"," [226 425  15]\n"," [226 426  15]\n"," [226 427  15]\n"," [226 428  15]\n"," [226 429  15]\n"," [226 430  15]\n"," [226 431  15]\n"," [226 432  15]\n"," [226 433  15]\n"," [226 434  15]\n"," [226 435  15]\n"," [227 425  15]\n"," [227 426  15]\n"," [227 427  15]\n"," [227 428  15]\n"," [227 429  15]\n"," [227 430  15]\n"," [227 431  15]\n"," [227 432  15]\n"," [227 433  15]\n"," [227 434  15]\n"," [227 435  15]\n"," [228 425  15]\n"," [228 426  15]\n"," [228 427  15]\n"," [228 428  15]\n"," [228 429  15]\n"," [228 430  15]\n"," [228 431  15]\n"," [228 432  15]\n"," [228 433  15]\n"," [228 434  15]\n"," [229 425  15]\n"," [229 426  15]\n"," [229 427  15]\n"," [229 428  15]\n"," [229 429  15]\n"," [229 430  15]\n"," [229 431  15]\n"," [229 432  15]\n"," [229 433  15]\n"," [229 434  15]\n"," [230 427  15]\n"," [230 428  15]\n"," [230 429  15]\n"," [230 430  15]\n"," [230 431  15]\n"," [230 432  15]\n"," [230 433  15]\n"," [230 434  15]\n"," [231 429  15]\n"," [231 430  15]\n"," [231 431  15]\n"," [231 432  15]\n"," [231 433  15]\n"," [231 434  15]\n"," [232 432  15]\n"," [232 433  15]]\n","class_array_index: 16  class_id: 3\n","mask position index: [[218 416  16]\n"," [218 417  16]\n"," [218 418  16]\n"," [219 414  16]\n"," [219 415  16]\n"," [219 416  16]\n"," [219 417  16]\n"," [219 418  16]\n"," [219 419  16]\n"," [219 420  16]\n"," [220 414  16]\n"," [220 415  16]\n"," [220 416  16]\n"," [220 417  16]\n"," [220 418  16]\n"," [220 419  16]\n"," [220 420  16]\n"," [220 421  16]\n"," [221 413  16]\n"," [221 414  16]\n"," [221 415  16]\n"," [221 416  16]\n"," [221 417  16]\n"," [221 418  16]\n"," [221 419  16]\n"," [221 420  16]\n"," [221 421  16]\n"," [222 413  16]\n"," [222 414  16]\n"," [222 415  16]\n"," [222 416  16]\n"," [222 417  16]\n"," [222 418  16]\n"," [222 419  16]\n"," [222 420  16]\n"," [222 421  16]\n"," [223 413  16]\n"," [223 414  16]\n"," [223 415  16]\n"," [223 416  16]\n"," [223 417  16]\n"," [223 418  16]\n"," [223 419  16]\n"," [223 420  16]\n"," [223 421  16]\n"," [224 413  16]\n"," [224 414  16]\n"," [224 415  16]\n"," [224 416  16]\n"," [224 417  16]\n"," [224 418  16]\n"," [224 419  16]\n"," [224 420  16]\n"," [224 421  16]\n"," [225 413  16]\n"," [225 414  16]\n"," [225 415  16]\n"," [225 416  16]\n"," [225 417  16]\n"," [225 418  16]\n"," [225 419  16]\n"," [225 420  16]\n"," [225 421  16]\n"," [225 422  16]\n"," [226 413  16]\n"," [226 414  16]\n"," [226 415  16]\n"," [226 416  16]\n"," [226 417  16]\n"," [226 418  16]\n"," [226 419  16]\n"," [226 420  16]\n"," [226 421  16]\n"," [226 422  16]]\n","class_array_index: 17  class_id: 3\n","mask position index: [[233 470  17]\n"," [233 471  17]\n"," [233 472  17]\n"," [233 473  17]\n"," [233 474  17]\n"," [233 475  17]\n"," [234 470  17]\n"," [234 471  17]\n"," [234 472  17]\n"," [234 473  17]\n"," [234 474  17]\n"," [234 475  17]\n"," [235 470  17]\n"," [235 471  17]\n"," [235 472  17]\n"," [235 473  17]\n"," [235 474  17]\n"," [235 475  17]\n"," [236 469  17]\n"," [236 470  17]\n"," [236 471  17]\n"," [236 472  17]\n"," [236 473  17]\n"," [236 474  17]\n"," [236 475  17]\n"," [237 469  17]\n"," [237 470  17]\n"," [237 471  17]\n"," [237 472  17]\n"," [237 473  17]\n"," [237 474  17]\n"," [238 469  17]\n"," [238 470  17]\n"," [238 471  17]\n"," [238 472  17]\n"," [238 473  17]\n"," [238 474  17]\n"," [239 468  17]\n"," [239 469  17]\n"," [239 470  17]\n"," [239 471  17]\n"," [239 472  17]\n"," [239 473  17]\n"," [239 474  17]\n"," [240 468  17]\n"," [240 469  17]\n"," [240 470  17]\n"," [240 471  17]\n"," [240 472  17]\n"," [240 473  17]\n"," [240 474  17]\n"," [241 468  17]\n"," [241 469  17]\n"," [241 470  17]\n"," [241 471  17]\n"," [241 472  17]\n"," [241 473  17]\n"," [241 474  17]\n"," [242 468  17]\n"," [242 469  17]\n"," [242 470  17]\n"," [242 471  17]\n"," [242 472  17]\n"," [242 473  17]\n"," [242 474  17]\n"," [243 468  17]\n"," [243 469  17]\n"," [243 470  17]\n"," [243 471  17]\n"," [243 472  17]\n"," [243 473  17]\n"," [243 474  17]\n"," [244 467  17]\n"," [244 468  17]\n"," [244 469  17]\n"," [244 470  17]\n"," [244 471  17]\n"," [244 472  17]\n"," [244 473  17]\n"," [244 474  17]\n"," [245 467  17]\n"," [245 468  17]\n"," [245 469  17]\n"," [245 470  17]\n"," [245 471  17]\n"," [245 472  17]\n"," [245 473  17]\n"," [245 474  17]\n"," [246 467  17]\n"," [246 468  17]\n"," [246 469  17]\n"," [246 470  17]\n"," [246 471  17]\n"," [246 472  17]\n"," [246 473  17]\n"," [246 474  17]\n"," [247 467  17]\n"," [247 468  17]\n"," [247 469  17]\n"," [247 470  17]\n"," [247 471  17]\n"," [247 472  17]\n"," [247 473  17]\n"," [248 466  17]\n"," [248 467  17]\n"," [248 468  17]\n"," [248 469  17]\n"," [248 470  17]\n"," [248 471  17]\n"," [248 472  17]\n"," [249 466  17]\n"," [249 467  17]\n"," [249 468  17]\n"," [249 469  17]\n"," [249 470  17]\n"," [249 471  17]\n"," [250 466  17]\n"," [250 467  17]\n"," [250 468  17]\n"," [250 469  17]\n"," [251 467  17]\n"," [251 468  17]\n"," [251 469  17]]\n","[(1, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (1, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (1, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (1, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (1, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]])), (3, array([[217, 366],\n","       [217, 367],\n","       [217, 368],\n","       ...,\n","       [563, 703],\n","       [563, 704],\n","       [563, 705]]))]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u9lwMY6Lvf68","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":149},"executionInfo":{"status":"ok","timestamp":1597840968260,"user_tz":-540,"elapsed":906,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"31bbc4a3-5ebc-4dd7-d642-452537ba3813"},"source":["np.transpose((mask_array > 0).nonzero())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[217, 366,  11],\n","       [217, 367,  11],\n","       [217, 368,  11],\n","       ...,\n","       [563, 703,   0],\n","       [563, 704,   0],\n","       [563, 705,   0]])"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"AvLK2Din4qj6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1597840306759,"user_tz":-540,"elapsed":125898,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"faacee01-6fa2-4045-e6cc-403f3f7cd53c"},"source":["# results[0]['masks']는 object 별로 mask가 전체 이미지에 대해서 layered된 image 배열을 가지고 있음.  \n","results[0]['rois'].shape, results[0]['scores'].shape, results[0]['class_ids'].shape, results[0]['masks'].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((18, 4), (18,), (18,), (633, 806, 18))"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"M3X_OSR44qkB","colab_type":"code","colab":{}},"source":["from mrcnn import visualize\n","\n","r = results[0]\n","class_names = [value for value in labels_to_names.values()]\n","visualize.display_instances(beatles_img_rgb, r['rois'], r['masks'], r['class_ids'], \n","                            class_names, r['scores'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"bz3ZF04B4qkI","colab_type":"code","colab":{}},"source":["import time\n","\n","wick_img = cv2.imread(os.path.join(default_dir, 'data/image/john_wick01.jpg'))\n","wick_img_rgb = cv2.cvtColor(wick_img, cv2.COLOR_BGR2RGB)\n","\n","def get_segment_result(img_array_list, verbose):\n","    \n","    start_time = time.time()\n","    results = model.detect(img_array_list, verbose=1)\n","    \n","    if verbose==1:\n","        print('## inference time:{0:}'.format(time.time()-start_time))\n","    \n","    return results\n","\n","r = get_segment_result([wick_img_rgb], verbose=1)[0]\n","visualize.display_instances(wick_img_rgb, r['rois'], r['masks'], r['class_ids'], \n","                            class_names, r['scores'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"15nba1_Q4qkN","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c7ewx0Nc4qkS","colab_type":"text"},"source":["### Video에 Segmentation 적용 \n","* MaskRCNN 패키지는 visualize.display_instances() 함수내부에서 matplotlib를 이용하여 자체 시각화를 수행. \n","* Video segment instance에 적용하기 위해서 bounding box와 instance masking을 적용하는 별도의 함수 생성. "]},{"cell_type":"code","metadata":{"id":"-I_TQgVo4qkT","colab_type":"code","colab":{}},"source":["from mrcnn.visualize import *\n","import cv2\n","\n","def get_segmented_image(img_array, boxes, masks, class_ids, class_names,\n","                      scores=None, show_mask=True, show_bbox=True, colors=None, captions=None):\n","   \n","    # Number of instances\n","    N = boxes.shape[0]\n","    if not N:\n","        print(\"\\n*** No instances to display *** \\n\")\n","    else:\n","        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n","    \n","\n","    # Generate random colors\n","    colors = colors or random_colors(N)\n","\n","    # Show area outside image boundaries.\n","    height, width = img_array.shape[:2]\n","\n","    masked_image = img_array.astype(np.uint32).copy()\n","\n","    for i in range(N):\n","        color = np.array(colors[i])*255\n","        color = color.tolist()\n","\n","        # Bounding box\n","        if not np.any(boxes[i]):\n","            # Skip this instance. Has no bbox. Likely lost in image cropping.\n","            continue\n","        y1, x1, y2, x2 = boxes[i]\n","        \n","        if show_bbox:\n","            cv2.rectangle(img_array, (x1, y1), (x2, y2), color, thickness=1 )\n","\n","        # Label\n","        if not captions:\n","            class_id = class_ids[i]\n","            score = scores[i] if scores is not None else None\n","            label = class_names[class_id]\n","            caption = \"{} {:.3f}\".format(label, score) if score else label\n","        else:\n","            caption = captions[i]\n","            \n","        cv2.putText(img_array, caption, (x1, y1+8), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), thickness=1)\n","        \n","        # Mask\n","        # 클래스별 mask 정보를 추출 \n","        mask = masks[:, :, i]\n","        if show_mask:\n","            # visualize 모듈의 apply_mask()를 적용하여 masking 수행.\n","            img_array = apply_mask(img_array, mask, color)\n","            \n","            # mask에 contour 적용. \n","            padded_mask = np.zeros(\n","                            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n","            padded_mask[1:-1, 1:-1] = mask\n","            contours = find_contours(padded_mask, 0.5)\n","            for verts in contours:\n","                # padding 제거. 아래에서 verts를 32bit integer로 변경해야 polylines()에서 오류 발생하지 않음. \n","                verts = verts.astype(np.int32)\n","                #x, y 좌표 교체\n","                verts = np.fliplr(verts) - 1\n","                cv2.polylines(img_array, [verts], True, color, thickness=1)\n","    \n","    return img_array\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"62ZhjG6W4qkY","colab_type":"text"},"source":["####  단일 IMAGE에 적용"]},{"cell_type":"code","metadata":{"id":"i2rbHnvC4qkZ","colab_type":"code","colab":{}},"source":["import time\n","\n","wick_img = cv2.imread(os.path.join(default_dir, 'data/image/john_wick01.jpg'))\n","wick_img_rgb = cv2.cvtColor(wick_img, cv2.COLOR_BGR2RGB)\n","\n","r = get_segment_result([wick_img_rgb], verbose=1)[0]\n","segmented_img = get_segmented_image(wick_img_rgb, r['rois'], r['masks'], r['class_ids'], \n","                                    class_names, r['scores'])\n","\n","plt.figure(figsize=(16, 16))\n","plt.imshow(segmented_img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YocPZevF4qkd","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wieILPng4qkh","colab_type":"text"},"source":["#### Video Segmentation 적용"]},{"cell_type":"code","metadata":{"id":"0xqKFu8X4qki","colab_type":"code","colab":{}},"source":["import time\n","\n","video_input_path = os.path.join(default_dir, 'data/video/John_Wick_small.mp4')\n","# video output 의 포맷은 avi 로 반드시 설정 필요. \n","video_output_path = os.path.join(default_dir, 'data/output/John_Wick_small_matterport01.avi')\n","\n","cap = cv2.VideoCapture(video_input_path)\n","codec = cv2.VideoWriter_fourcc(*'XVID')\n","fps = round(cap.get(cv2.CAP_PROP_FPS))\n","\n","vid_writer = cv2.VideoWriter(video_output_path, codec, fps, (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n","\n","total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","print(\"총 Frame 개수: {0:}\".format(total))\n","\n","frame_index = 0\n","while True:\n","    \n","    hasFrame, image_frame = cap.read()\n","    if not hasFrame:\n","        print('End of frame')\n","        break\n","    \n","    frame_index += 1\n","    print(\"frame index:{0:}\".format(frame_index), end=\" \")\n","    r = get_segment_result([image_frame], verbose=1)[0]\n","    segmented_img = get_segmented_image(image_frame, r['rois'], r['masks'], r['class_ids'], \n","                                    class_names, r['scores'])\n","    vid_writer.write(segmented_img)\n","    \n","vid_writer.release()\n","cap.release()       "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ss6ZL3xr_Vr4","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. 이를 위해 google drive를 colab에 mount 수행. \n","import os, sys \n","from google.colab import drive \n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iGCgyEdU_b_N","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. \n","## My Drive 디렉토리 이름에 공란이 있으므로 ' '로 묶습니다. \n","!cp /content/DLCV/data/output/John_Wick_small_matterport01.avi '/content/gdrive/My Drive/John_Wick_small_matterport01.avi'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qYJJbHmE4qkr","colab_type":"text"},"source":["#### 다른 동영상에 적용. "]},{"cell_type":"code","metadata":{"id":"PErrMWnW4qks","colab_type":"code","colab":{}},"source":["video_input_path = os.path.join(default_dir, 'data/video/London_Street.mp4')\n","# video output 의 포맷은 avi 로 반드시 설정 필요. \n","video_output_path = os.path.join(default_dir, 'data/output/London_Street_matterport01.avi')\n","\n","cap = cv2.VideoCapture(video_input_path)\n","codec = cv2.VideoWriter_fourcc(*'XVID')\n","fps = round(cap.get(cv2.CAP_PROP_FPS))\n","vid_writer = cv2.VideoWriter(video_output_path, codec, fps, (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n","\n","total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","print(\"총 Frame 개수: {0:}\".format(total))\n","\n","import time\n","\n","frame_index = 0\n","while True:\n","    \n","    hasFrame, image_frame = cap.read()\n","    if not hasFrame:\n","        print('End of frame')\n","        break\n","    \n","    frame_index += 1\n","    print(\"frame index:{0:}\".format(frame_index), end=\" \")\n","    r = get_segment_result([image_frame], verbose=1)[0]\n","    segmented_img = get_segmented_image(image_frame, r['rois'], r['masks'], r['class_ids'], \n","                                    class_names, r['scores'])\n","    vid_writer.write(segmented_img)\n","    \n","vid_writer.release()\n","cap.release()       \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"37umzlI34qk1","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. \n","## My Drive 디렉토리 이름에 공란이 있으므로 ' '로 묶습니다. \n","!cp /content/DLCV/data/output/London_Street_matterport01.avi '/content/gdrive/My Drive/London_Street_matterport01.avi'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r2eK3C7uFlyA","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}